% Publication patterns in Evolution and Ecology
% Zoltán Barta; Tibor Magura
% `r date()`

---
bibliography: /home/apa/notes/articles.bib
natbib: true
biblio-files: /home/apa/notes/articles.bib
biblio-style: /home/apa/lib/texinputs/AmNat
biblio-title: References
fontsize: 12pt
papersize: a4paper
include-before:
- \linenumbers
header-includes:
- \usepackage{lineno}
- \usepackage{double_spaced}
geometry:
- margin=1in
---

```{r set-up-knitr, include=FALSE}
source("~/lib/markdown/produce_output.R")
```

# TODOs

- calculate statistics for cut off values other than 0.4
	- plot the number of guilds, percentage of authors in guilds and percentage of edged affected as a function of the cut off value
- use the MTMT dataset to calculate cartels for different scientific fields

# Set up

Here we load some packages and custom codes.

```{r set-up}
## set the working directory
## load the libraries
library(openxlsx)
library(igraph)
library(lme4)
library(emmeans)
## load local code
source("process_MTMT-json-functions.R")
## set options
par(xpd=FALSE)
```

# The dblp dataset

We downloaded the [dblp publication database](https://dblp.org), which covers computational sciences. Then we extracted all article records from the database `xml` which have a `doi.org` id. During the extraction we dropped all but the `author`, `year` and `doi` fields. Next, we imported the resulted `xml` file into `R` and created a list from it. The process is documented in `dblp-data/Makefile`.

## Load the dblp dataset

Now we load the dataset.

```{r load-dblp}
load("dblp-data/parsed-dblp-list.Rdata")
length(dblp.ls)
head(dblp.ls, 4)
```

## Some description about the dataset

The dblp dataset contains more than one and half million records. The distribution of articles over the years is as follows.

```{r dblp-years}
years <- sapply(dblp.ls, function(y) y$year)
plot(table(years), ylab="number of articles")
```

The distribution of number of authors by articles.

```{r dblp-authors}
n.authors <- sapply(dblp.ls, function(y) length(y$authors))
plot(table(n.authors))
plot.loglog(n.authors, pch=16, bty="l", xlab="number of authors per paper",
						ylab="frequency")
```

The number of distinct authors in the dataset:

```{r dblp-distinct-authors}
d.authors <- unlist(lapply(dblp.ls, function(y) y$authors))
length(d.authors)
length(unique(d.authors))
t.authors <- table(d.authors)
t.authors <- sort(t.authors)
plot.loglog(as.numeric(t.authors), pch=16, bty="l",
		 xlab="number of papers per author", ylab="frequency")
```

## Reducing the dblp dataset

We have a huge number of articles so for the first time we concentrate only articles between 2001 and 2010.

```{r select-2001-2010}
years <- as.numeric(years)
i <- years >= 2001 & years <= 2010
sum(i)
dblp.red <- dblp.ls[i]
rm("dblp.ls")
gc()
```

This is still a huge number, but we make a try.

```{r dblp-authors}
n.authors <- sapply(dblp.red, function(y) length(y$authors))
plot(table(n.authors))
plot.loglog(n.authors, pch=16, bty="l", xlab="number of authors per paper",
						ylab="frequency")
```


```{r dblp-distinct-authors-red}
a.authors <- unlist(lapply(dblp.red, function(y) y$authors))
length(a.authors)
d.authors <- unique(a.authors)
length(d.authors)
t.authors <- table(a.authors)
t.authors <- sort(t.authors)
plot.loglog(as.numeric(t.authors), pch=16, bty="l",
		 xlab="number of papers per author", ylab="frequency")
```

## Process the article data

We are create a sparse matrix and fill it with the coauthorship data.

```{r dblp-create-Matrix}
p.ls <- dblp.red[1:100]
d.authors <- unique(unlist(lapply(p.ls, function(y) y$authors)))
d.mat <- Matrix(0.0, ncol=length(d.authors), nrow=length(d.authors))
colnames(d.mat) <- d.authors
rownames(d.mat) <- d.authors
for(p in p.ls) {
	n.a <- length(p$authors)
	for(a in p$authors) {
		d.mat[a, a] <- d.mat[a, a] + 1
	}
	if(n.a > 1) {
		for(i in 1:(n.a-1)) {
			a1 <- p$authors[i]
			for(j in (i+1):n.a) {
				a2 <- p$authors[j]
				d.mat[a1, a2] <- d.mat[a1, a2] + 1
			}
		}
	}
}
for(i  in 1:(ncol(d.mat)-1)) {
	for(j in (i+1):ncol(d.mat)) {
		d.sec <- d.mat[i,j] + d.mat[j,i]
		if(d.sec > 0) {
			d.uni <- d.mat[i, i] + d.mat[j, j] - d.sec
			d.mat[i, j] <- d.sec/d.uni
			d.mat[j, i] <- 0
		}
	}
}
g.dblp <- graph.adjacency(d.mat, mode="upper", weighted=TRUE, diag=FALSE)
```


# The MTMTM dataset

## Create the publication database

We collected publication data from the Hungarian publication database, [MTMT](http://www.mtmt.hu). As we do not have the MTMT ID of large number of authors, we use a recursive technique to collect the publication data. In this recursive algorithm we download the publication records of some researchers and then use their record to obtain further IDs. We repeat this procedure for the newly downloaded records too, for a couple of times.

First, we create a database of the seed IDs. The file `mtmt_azonositok.xlsx` was collected by TM, while the file `BOI.staff.txt` contains the IDs of the researchers at the Institute of Biology and Ecology, University of Debrecen, compiled by ZB.

```{r create-seeds, eval=FALSE}
m.ids <- read.xlsx("mtmt_azonositok.xlsx")
BOI.ids <- read.table(file="~/Hivatal/intezet/publikaciok/BOI_staff.txt",
											sep="\t", header=TRUE, stringsAsFactors=FALSE)
seed.ids <- unique(c(m.ids$MTMT.azonosító, BOI.ids$mtmt.id))
```

Next, we download the MTMT records for the seed IDs.

```{r download-first, eval=FALSE}
download.MTMT.batch(seed.ids)
```

Next, we process the downloaded `json` files and get the MTMT IDs of the coauthors. For this we write a function, which takes the list of publication records and returns the vector of coauthors' IDs. In a second function we wrap the `get.coauthors` function to process all the files in the data directory. And now, the actual computations to get the list of coauthors for each downloaded author.

```{r get-coauthors-1, eval=FALSE}
seed.ids2 <- get.all.coauthors()
```

Now, we start the second round of getting author records.

```{r download-second, eval=FALSE}
download.MTMT.batch(seed.ids2)
```

The third round.

```{r download-third, eval=FALSE}
seed.ids3 <- get.all.coauthors(pattern=".*2019-11-24\\.json$")
#download.MTMT.batch(seed.ids3)
```

## Load publication data

We load the publication records from the local repository. At the same time we also process them and calculate some basic measures for each article. We only consider those articles which has valid ranking (D1, Q1, ...), i.e. those having an impact factor.

We calculate the following measures for each article:

- the paper unique MTMT ID,
- the types of the paper, e.g. article, review,
- year of publication,
- the paper's rank according to [Scimago Journal ranking](https://www.scimagojr.com/),
- the number of independent citations the paper received so far,
- the number of people authored the paper,
- the order of the focal author in the author list,
- is the focal author the first author,
- is the focal author the last author.


```{r load-records}
saved.records <- "load-records.Rdata"
if(file.exists(saved.records)) {
	load(saved.records)
} else {
	json.files <- list.files(path="MTMT-downloads", pattern=".*\\.json",
													 full.names=TRUE)
	papers.ls <- list()
	au.info <- list()
	au.ids <- list()
	i <- 1
	for(f in json.files) {
		#if(i %% 100 == 0) print(i)
		print(i)
		id <- sub(".*/(.*)_.*", "\\1", f)
		id.hash <- hash.id(as.numeric(id))
		cikkek <- read.MTMT(f)
		if(length(cikkek) == 0 | is.na(cikkek)[1]) {
			next
		} else {
			au.ids[[id.hash]] <- id
			au.info[[id.hash]] <- p.author.label(cikkek[[1]], id)
			papers.ls[[id.hash]] <- pub.measures(cikkek, id)
		}
		if(i %% 1000 == 0) {
			save(au.ids, au.info, papers.ls, file=saved.records)
			gc()
		}
		i <- i+1
	}
	save(au.ids, au.info, papers.ls, file=saved.records)
}
au.info <- unlist(au.info)
au.ids <- unlist(au.ids)
```

We create an author database, to contain the authors' MTMT ID, name, affiliation and subject field. For some unknown reason `au.info` contain two less records than `au.ids` and `papers.ls`, so first we remove these records from them.

```{r rm-au-id}
i <- names(au.ids) %in% names(au.info)
au.ids <- au.ids[i]
i <- names(papers.ls) %in% names(au.info)
papers.ls <- papers.ls[i]
```

Now the creation of the database.

```{r author-info}
author.info <- data.frame(mtmt.id=au.ids, info=au.info)
n <- sub(".*\\[(.*)\\].*", "\\1", author.info$info)
n <- sub(", szerző", "", n)
n <- sub("\\(.*", "", n)
n <- sub(" *$", "", n)
n <- gsub(",", "", n)
author.info$name <- n
aff <- sub(".*\\] *", "", author.info$info)
author.info$affiliation <- aff
ff <- sub(".*\\[(.*)\\].*", "\\1", author.info$info)
ff <- sub(".*\\((.*)\\).*", "\\1", ff)
author.info$field <- ff
author.info <- author.info[,c(1,3:5,2)]
```

Because we only consider papers with ranks, several author remained without publications. We discard the records of those people.

```{r discard-zero.pubs}
l <- sapply(papers.ls, nrow)
n.p <- as.numeric(names(table(l)))
f.p <- as.numeric(table(l))
plot.loglog(l, bty="l", pch=16, xlab="number of papers per authors",
						ylab="frequency")
papers.ls <- papers.ls[l != 0]
```

We also update the author database.

```{r update-authors}
author.info <- author.info[names(papers.ls),]
```

We create a paper database too. This contains data about all distinct papers in the records.

```{r create-paper-df}
papers.Rdata <- "papers-df.Rdata"
if(file.exists(papers.Rdata)) {
	load(papers.Rdata)
} else {
	papers.df <- papers.ls[[1]]
	for(p in papers.ls[-1]) {
		papers.df <- rbind(papers.df, p)
	}
	save(papers.df, file=papers.Rdata)
}
```

As several fields (e.g. `first.au`) are irrelevant for this data frame we remove them.

```{r rm-field-paper-df}
papers.df$types <- NULL
papers.df$r.author <- NULL
papers.df$first.au <- NULL
papers.df$last.au <- NULL
```

Next we remove the duplicates.
```{r rm-duplicates}
pids <- tapply(1:nrow(papers.df), papers.df$id, function(y) min(y))
papers.df <- papers.df[pids,]
f <- as.character(papers.df$ranks)
f <- factor(f, levels=c("D1", paste("Q", 1:4, sep="")))
papers.df$ranks <- f
```


## Analyses of the whole dataset

### Some preliminary analyses

The number of authors in the analyses:
```{r n-authors}
length(papers.ls)
```

The number of unique papers on which the analyses base, i.e. the union of the sets of the authors' papers:
```{r n-papers}
p <- lapply(papers.ls, function(y) y$id)
ta <- table(unlist(p))
length(ta)
```

The total number of papers authored by the researchers in the database:
```{r n-total-papers}
sum(ta)
```

A paper, in average, occurs in the dataset several times:
```{r mtmt-mult-occ}
sum(ta)/length(ta)
```

The number of papers authored by only one researcher:
```{r n-alone}
table(ta)['1']
```

The log-log distribution of the number of papers by authors.
```{r dist-papers}
l <- sapply(p, length)
summary(l)
bins <- 2^seq(-1,10,1)
ll <- cut(l, bins)
t.ll <- table(ll)
m.bins <- rowMeans(cbind(bins[-length(bins)], bins[-1]))
plot.loglog(l, pch=16, bty="l", xlab="number of papers per author",
						ylab="frequency")
```

The number of authors on a paper.

```{r mtmt-no-authors}
summary(papers.df$n.authors)
plot.loglog(papers.df$n.authors, pbins=seq(-1, 13, 1), pch=16, bty="l",
						xlab="number of authors per paper", ylab="frequency")
```


### Calculate publication measures

We calculate a couple of derived bibliographic measures for each author:

- number of papers
- total number of independent citations
- Hirsch index
- total number of coauthors
- number of D1 papers
- average number of citations per papers
- proportion of D1 papers
- number of papers weighted by
	- the equal contribution scheme
	- the sequence determined contribution scheme
	- the first, last author emphasis scheme
	- the bonus for first authorship scheme
	- the bonus for last authorship scheme
- number of independent citations weighted by the same schemes as used for the number of papers
- number of D1 papers weighted by the same schemes as used for the number of papers

```{r calc-pup-measures}
sum.pubs <- NULL
for(s in papers.ls) {
	r <- calc.bib.measures(s)
	if(is.null(sum.pubs)) {
		sum.pubs <- data.frame(t(r))
	} else {
		sum.pubs <- rbind(sum.pubs, r)
	}
}
rownames(sum.pubs) <- names(papers.ls)
```

### Build collaboration network

We build a collaboration network based on the proportion of shared publications, $p_{A,B}$: the weight of an edge is the number of shared papers divided by the sum of the shared papers and the papers unique to each author connected by the edge.

$$
p_{A,B} = \frac{A \cap B}{A \cup B}
$$

First, we create an association matrix from the bibliography data:

```{r create-assoc-mat}
graph.file <- "assoc_mat.Rdata"
if(file.exists(graph.file)) {
	load(graph.file)
} else {
	#assoc.mat <- create.assoc.mat(papers.ls)
	assoc.mat <- create.assoc.mat.from.file(papers.ls)
	#assoc.mat <- assoc.mat[names(papers.ls), names(papers.ls)]
	save(assoc.mat, file=graph.file)
}
```

It seems, that in a couple of cases the MTMT database contains error, i.e. the list of common articles of pairs of authors does not match. We have 72 such cases. We simply ignore these mismatches and use only the upper triangle of the association matrix to create the collaboration graph.

```{r create-pub-graph}
d.a <- assoc.mat - t(assoc.mat)
sum(d.a != 0)
g.pubs <- graph.adjacency(assoc.mat, mode="upper", weighted=TRUE,
													diag=FALSE)
vcount(g.pubs)
ecount(g.pubs)
```

Then we plot the graph. Here the width of the edges is proportional to $p_{A,B}$, i.e. the proportion of shared articles. The size of the nodes is proportional the number of edges, i.e. to the number of coauthors.

```{r plot-assoc-mat}
#set.seed(11)
cols <- rep("lightblue", length(V(g.pubs)))
V(g.pubs)$color <- cols
#V(g.pubs)$size = 0.1
#V(g.pubs)$size = 0.1*sqrt(sum.pubs$n.D1)
V(g.pubs)$size = 0.1*sqrt(degree(g.pubs))
png(file="full-graph-map-D1.png", width=20000, height=20000)
plot(g.pubs, vertex.label.cex=0.1, edge.width=10*E(g.pubs)$weight)
dev.off()
```


### Strongly connected components

The next step is to identify the strongly connected components. We define strongly connected components as nodes connected with edges of weight more than 0.4. Hereafter, we refer these strongly connected components as _guilds_.

```{r hist-weights}
w.cut <- 0.5
w <- E(g.pubs)$weight
hist(w, seq(0,1,0.01), main="", xlab="edge weight")
abline(v=w.cut, lty=2)
(p.cut <- sum(w >= w.cut)/length(w))
text(0.8, 15000, paste(round(p.cut*100, 2), "% of edges", sep=""))
```

As the above histogram shows only a small proportion of edges have weights more than 0.4.

The following obtains these guilds.

```{r strong-comps}
g.pubs.st.red <- subgraph.edges(g.pubs, E(g.pubs)[E(g.pubs)$weight >= w.cut])
comp.red <- cluster_fast_greedy(g.pubs.st.red)
memb.red <- membership(comp.red)
pdf(file="guilds-all.pdf", width=20, height=20)
plot(g.pubs.st.red, vertex.label.cex=0.75, edge.width=2, edge.color="black")
dev.off()
```

Some description of these components.

```{r descr-strong-comps}
t.memb.red <- table(memb.red)
length(t.memb.red)
vcount(g.pubs.st.red)
vcount(g.pubs.st.red)/vcount(g.pubs)
(t.size.sc <- table(t.memb.red))
barplot(t.size.sc, xlab="size of guilds",
				ylab="frequency")
```

The above shows that most of these guilds contain two authors, but there are several components with at least four authors. About 20% of all authors take part in these components.

```{r plot-evoeco-guilds}
g.pubs.st <- subgraph.edges(g.pubs, E(g.pubs)[E(g.pubs)$weight > w.cut],
													delete.vertices=FALSE)
E(g.pubs.st)$weight <- 1
coords <- layout_components(g.pubs, layout_nicely)
png(file="full-graph-map-guilds.png", width=20000, height=20000)
plot(g.pubs, vertex.label.cex=0.01, edge.width=0.1, layout=coords)
plot(g.pubs.st, vertex.label.cex=0.01, edge.width=1, edge.color="red",
		 layout=coords, add=TRUE)
dev.off()
```

The guilds scattered all over the publication graph.

Next, we investigate how attributes of cartels changes with the cut off values.

```{r mtmt-cartels-vs-cutoff}
cartels.cutoff <- data.frame()
cutoffs <- seq(0.3, 0.95, 0.01)
for(w.cut in cutoffs) {
	r <- cartels.comp(g.pubs, w.cut)
	cartels.cutoff <- rbind(cartels.cutoff, r)
}
names(cartels.cutoff) <- names(r)
cartels.cutoff$cutoff <- cutoffs
```

Some plots:

```{r mtmt-plot-cutoffs}
layout(1:2)
plot(n.authors ~ cutoff, cartels.cutoff, type="o", log="xy")
plot(max.cartel ~ cutoff, cartels.cutoff, type="o", log="xy")
layout(1)

plot(p.authors ~ cutoff, cartels.cutoff, type="o", log="xy")
plot(n.authors ~ n.cartels, cartels.cutoff, log="xy")
plot(I(n.authors/n.cartels) ~ cutoff, cartels.cutoff)
plot(p.edges ~ cutoff, cartels.cutoff)
plot(I(n.authors/n.cartels) ~ p.edges, cartels.cutoff)
```

### Productivity of guilds

First we identify authors part of a guild in the productivity database.

```{r guild-ID}
full.au <- sum.pubs
guild.authors <- names(V(g.pubs.st.red))
non.guild.authors <- names(V(g.pubs))
non.guild.authors <- non.guild.authors[!(non.guild.authors %in%
																					 guild.authors)]
i <- rownames(full.au) %in% guild.authors
j <- rownames(full.au) %in% non.guild.authors

full.au$guild.member <- NA
full.au$guild.member[i] <- "yes"
full.au$guild.member[j] <- "no"
full.au$guild.member <- factor(full.au$guild.member)
```

Next, we compare the productivity of guilds to that of 'guilds' compiled from random individuals. We define the following function to do the calculations.

The first function calculates several measures of guild productivity. Guild productivity is measured for both the number of papers and citations. Guilds are characterised by (i) the total number of papers (and their citations) produced by the guild as a whole, (ii) the total number of papers (and their citations) produced by the guild members (in this case papers and citations can overlap between members), and (iii) the weighted numbers of papers (and their citations) produced by the members according to several scheme.

The second function generates `n.rep` guilds randomly compiled from authors not being member of any guilds and then calculates the above measures for each random guild.

The third function performs a randomisation test to see if the given measure for the focal guild differs from that of the random guilds.

The fourth function calculates the quantile of the guild measures relative to the distribution of random guild values.

```{r prod-fun}
guild.productivity <- function(guild, cikkek=papers.ls, szerzok=ee.prod) {
	g.cikkek <- cikkek[guild]
	p <- lapply(g.cikkek, function(sz) {x <- sz$citations; names(x) <- sz$id; x})
	pp <- lapply(g.cikkek, function(sz) {x <- sz$ranks; names(x) <- sz$id; x})
	d <- data.frame(n=unlist(sapply(p, names)), v=unlist(p), vv=unlist(pp))
	ud <- unique(d)
	r <- numeric()
	r["g.papers"] <- nrow(ud)
	r["g.citations"] <- sum(ud$v)
	r["g.D1"] <- sum(ud$vv == "D1")
	r["m.papers"] <- sum(szerzok[guild, "n.papers"])
	r["m.citations"] <- sum(szerzok[guild, "n.citations"])
	r["m.D1"] <- sum(szerzok[guild, "n.D1"])
	n <- names(szerzok)
	n <- n[grep("^w.*papers$", n)]
	for(nn in n) {
		r[nn] <- sum(szerzok[guild, nn])
		nc <- sub("papers$", "citations", nn)
		r[nc] <- sum(szerzok[guild, nc])
		nd <- sub("papers$", "D1", nn)
		r[nd] <- sum(szerzok[guild, nd])
	}
	r/length(guild)
}
rnd.guild.productivity <- function(guild.size, n.rep=1000, cikkek=papers.ls,
																		szerzok=ee.prod) {
	n.c.a <- rownames(szerzok)[szerzok$guild.member == "no"]
	res <- matrix(0, ncol=21, nrow=n.rep)
	for(i in 1:n.rep) {
		s <- sample(n.c.a, guild.size)
		r <- guild.productivity(s, cikkek=cikkek, szerzok=szerzok)
		res[i,] <- r
	}
	colnames(res) <- names(r)
	res
}
guild.productivity.test <- function(guild, p.value=0.05, cikkek=papers.ls,
																		szerzok=ee.prod) {
	res.g <- guild.productivity(guild, cikkek=cikkek, szerzok=szerzok)
	res.r <- rnd.guild.productivity(length(guild), 999, cikkek, szerzok)
	res.r <- rbind(res.g, res.r)
	value <- res.g
	l.crit <- numeric(ncol(res.r))
	u.crit <- numeric(ncol(res.r))
	for(i in 1:ncol(res.r)) {
		p <- quantile(res.r[,i], c(p.value/2, 1-p.value/2))
		l.crit[i] <- p[1]
		u.crit[i] <- p[2]
	}
	data.frame(value=res.g, l.crit=l.crit, u.crit=u.crit,
						 sig.mark=ifelse(l.crit < res.g & res.g < u.crit, "", "*"),
						 variable=names(res.g))
}
guild.productivity.q <- function(guild, p.value=0.05, n.rep=999,
																 cikkek=papers.ls, szerzok=ee.prod) {
	res.g <- guild.productivity(guild, cikkek=cikkek, szerzok=szerzok)
	res.r <- rnd.guild.productivity(length(guild), n.rep, cikkek, szerzok)
	res.r <- rbind(res.g, res.r)
	d <- numeric(ncol(res.r))
	m <- numeric(ncol(res.r))
	for(i in 1:ncol(res.r)) {
		d[i] <- sum(res.r[,i] > res.g[i])
		m[i] <- mean(res.r[,i])
	}
	data.frame(measure=names(res.g), value=res.g, rnd.mean=m,
						 quantile=d/nrow(res.r), guild.size=length(guild))
}
```

In the following we calculate the statistics for the guilds identified previously.

```{r guild-prod}
l.memb.red <- tapply(names(memb.red), memb.red, unique)
l <- sapply(l.memb.red, length)
i <- names(l.memb.red)[order(l, decreasing=TRUE)]
l.memb.red <- l.memb.red[i]
gd.file <- "guild_measures.Rdata"
if(file.exists(gd.file)) {
	load(gd.file)
} else {
	cl.p <- lapply(l.memb.red, guild.productivity.q, szerzok=full.au)
	cl.df <- data.frame()
	for(n in names(cl.p)) {
		l <- cl.p[[n]]
		l$guild <- n
		rownames(l) <- NULL
		cl.df <- rbind(cl.df, l)
	}
	cl.df$sig <- ifelse(cl.df$quantile > 0.975 | cl.df$quantile < 0.025, "*", "")
	cl.df$g2rnd <- cl.df$value/cl.df$rnd.mean
	save(cl.df, file=gd.file)
}
```

And finally, some analyses.

```{r analyse-guild-prod}
cits <- grepl("papers$", cl.df$measure)
m.papers <- lmer(log10(g2rnd) ~ measure + (1|guild), cl.df, subset=cits)
drop1(m.papers, test="Chisq")
summary(m.papers)
(em.p <- emmeans(m.papers, ~measure, type="response"))
pairs(em.p)
plot(em.p, horizontal=FALSE, xlab="measures", ylab="ratio of focal to random",
		 comparison=TRUE)
```

The result of the mixed effect model clearly shows that in guilds members achieve higher success if one considers success as the sum of the achievements documented individually (here number of papers) than when one measures the composite productivity of the whole guild. Even using the weighted individual measures does not help this situation. This analyses were based on all guilds identified.

```{r analyse-guild-prod-citations}
cits <- grepl("citations$", cl.df$measure)
m.citations <- lmer(log10(g2rnd+1) ~ measure + (1|guild), cl.df, subset=cits)
drop1(m.citations, test="Chisq")
summary(m.citations)
(em.c <- emmeans(m.citations, ~measure, type="response"))
pairs(em.c)
plot(em.c, horizontal=FALSE, xlab="measures", ylab="ratio of focal to random",
		 comparison=TRUE)
```

Analysing the citation measures shows the same patterns, guild members have higher success if we consider their productivity independently from each other.

```{r analyse-guild-prod-D1}
cits <- grepl("D1$", cl.df$measure)
m.D1 <- lmer(log10(g2rnd+1) ~ measure + (1|guild), cl.df, subset=cits)
drop1(m.D1, test="Chisq")
summary(m.D1)
(em.d <- emmeans(m.D1, ~measure, type="response"))
pairs(em.d)
plot(em.d, horizontal=FALSE, xlab="measures", ylab="ratio of focal to random",
		 comparison=TRUE)
```


We now analyse only those guilds which show higher than random productivity on the basis of the unweighted individual measure.

```{r analyse-guild-prod-1}
i <- grepl("^m\\.", cl.df$measure) & cl.df$g2rnd > 1
success.guilds <- as.character(cl.df$guild)[i]
i <- cl.df$guild %in% success.guilds
m.1 <- lmer(log10(g2rnd) ~ measure + (1|guild), cl.df, subset=i & !cits)
drop1(m.1, test="Chisq")
summary(m.1)
(em.1 <- emmeans(m.1, ~measure, type="response"))
pairs(em.1)
plot(em.1, horizontal=FALSE, xlab="measures", ylab="ratio of focal to random",
		 comparison=TRUE)
```

We arrived at the same conclusions; being part of a guild is advantageous if individual measures are considered.

### Diversity in cartels

A major difference between manufactures (groups where individuals with different skills work together) and cartels (group of individuals collude to increase publication counts) is the diversity of within group expertise. In manufactures one would expect a high diversity while in cartels individuals do the same. A further distinction can be the diversity of affiliations. In manufactures individuals can come from many different places, while in cartels they likely come from the same place. To make a distinction between these two work models we first download data about the authors and then analyse their expertise and their affiliation.

#### Download individuals' data

```{r mtmt-download-authors, eval=FALSE}
download.MTMT.authors.batch(as.character(author.info$mtmt.id))
```

Get the speciality.

```{r mtmt-get-spec-1}
json.list <- list.files(path="MTMT-downloads/", pattern=".*-author.json$",
												full.names=TRUE)
author.ls <- list()
for(f in json.list) {
	mtmt.id <- sub(".*\\/([0-9]+)_.*", "\\1", f)
	author.ls[[mtmt.id]] <- read.MTMT(f)
}
sci.fields <- sapply(author.ls,
										 function(a) if(is.null(a$auxName)) {NA} else {a$auxName})
sci.fields <- gsub("\\<a ", "", sci.fields)
sci.fields <- gsub("\\<és\\>", "", sci.fields)
sci.fields <- tolower(gsub("[-,)(]", "", sci.fields))
sci.fields <- gsub(" +", " ", sci.fields)
sci.ta <- sort(table(sci.fields))
names(sci.fields) <- sapply(as.numeric(names(sci.fields)), hash.id)
author.info$scientific.field <- NA
author.info[names(sci.fields), "scientific.field"] <- sci.fields
```

### Analyses of members

```{r test-guild-member-prod}
(w.papers <- wilcox.test(n.papers ~ guild.member, full.au))
(wi.ec.papers <- wilcox.test(w.ec.papers ~ guild.member, full.au))
layout(matrix(1:2, ncol=2))
boxplot(n.papers ~ guild.member, full.au, log="y", xlab="guild member",
				ylab="number of papers",
				main=paste("Wilcoxon p = ", round(w.papers$p.value, 3)))
boxplot(I(w.ec.papers+1) ~ guild.member, full.au, log="y",
				xlab="guild member", ylab="weighted number of papers",
				main=paste("Wilcoxon p = ", round(wi.ec.papers$p.value, 3)))
layout(1)

(w.citations <- wilcox.test(n.citations ~ guild.member, full.au))
(wi.ec.citations <- wilcox.test(w.ec.citations ~ guild.member, full.au))
layout(matrix(1:2, ncol=2))
boxplot(I(n.citations+1) ~ guild.member, full.au, log="y",
				xlab="guild member", ylab="number of citations",
				main=paste("Wilcoxon p = ", round(w.citations$p.value, 3)))
boxplot(I(w.ec.citations+1) ~ guild.member, full.au, log="y",
				xlab="guild member", ylab="weighted number of citations",
				main=paste("Wilcoxon p = ", round(wi.ec.citations$p.value, 3)))
layout(1)

(w.D1 <- wilcox.test(n.D1 ~ guild.member, full.au))
(wi.ec.D1 <- wilcox.test(w.ec.D1 ~ guild.member, full.au))
layout(matrix(1:2, ncol=2))
boxplot(I(n.D1+1) ~ guild.member, full.au, log="y",
				xlab="guild member", ylab="number of D1 papers",
				main=paste("Wilcoxon p = ", round(w.D1$p.value, 3)))
boxplot(I(w.ec.D1+1) ~ guild.member, full.au, log="y",
				xlab="guild member", ylab="weighted number of D1 papers",
				main=paste("Wilcoxon p = ", round(wi.ec.D1$p.value, 3)))
layout(1)
```

Authors in guild are more affected by weighting productivity.

Next we investigate, how the authors rank changes if switch from unweighted to weighted publication measures.

```{r guild-ranks}
par(xpd=FALSE)
r.n.papers <- rank(full.au$n.papers)
r.flae.papers <- rank(full.au$w.flae.papers)
d.r <- r.flae.papers - r.n.papers
(w <- wilcox.test(d.r ~ guild.member, full.au))
boxplot(d.r ~ guild.member, full.au, xlab="guild member",
				ylab="change in rank: number of papers",
				main=paste("Wilcoxon p =", round(w$p.value, 3)))
abline(h=0, lty=2)

r.n.citations <- rank(full.au$n.citations)
r.flae.citations <- rank(full.au$w.flae.citations)
d.r <- r.flae.citations - r.n.citations
(w <- wilcox.test(d.r ~ guild.member, full.au))
boxplot(d.r ~ guild.member, full.au, xlab="guild member",
				ylab="change in rank: number of citations",
				main=paste("Wilcoxon p =", round(w$p.value, 4)))
abline(h=0, lty=2)

r.n.D1 <- rank(full.au$n.D1)
r.flae.D1 <- rank(full.au$w.flae.D1)
d.r <- r.flae.D1 - r.n.D1
(w <- wilcox.test(d.r ~ guild.member, full.au))
boxplot(d.r ~ guild.member, full.au, xlab="guild member",
				ylab="change in rank: number of D1 papers",
				main=paste("Wilcoxon p =", round(w$p.value, 4)))
abline(h=0, lty=2)
```

Here below, compare how the ranks of authors change when switching from unweighted to weighted measures, but now we compare authors of similar ranks.

```{r comp-similar-ranks}
o <- order(r.n.papers)
cm <- full.au$guild.member[o]
dr <- d.r[o]
i.c <- (1:nrow(full.au))[cm == "yes"]
i.c <- i.c[!is.na(i.c)]
i.p <- i.c - 1
i.p <- i.p[cm[i.p] == "no"]
i.n <- i.c + 1
i.n <- i.n[cm[i.n] == "no"]
(w <- wilcox.test(dr[i.c], c(dr[i.n],dr[i.p])))
boxplot(list(no=c(dr[i.p], dr[i.n]), yes=dr[i.c]), xlab="guild member",
				ylab="change in rank: number of papers",
				main=paste("Wilcoxon p =", round(w$p.value, 4)))
abline(h=0, lty=2)

o <- order(r.n.citations)
cm <- full.au$guild.member[o]
dr <- d.r[o]
i.c <- (1:nrow(full.au))[cm == "yes"]
i.c <- i.c[!is.na(i.c)]
i.p <- i.c - 1
i.p <- i.p[cm[i.p] == "no"]
i.n <- i.c + 1
i.n <- i.n[cm[i.n] == "no"]
(w <- wilcox.test(dr[i.c], c(dr[i.n],dr[i.p])))
boxplot(list(no=c(dr[i.p], dr[i.n]), yes=dr[i.c]), xlab="guild member",
				ylab="change in rank: number of citations",
				main=paste("Wilcoxon p =", round(w$p.value, 4)))
abline(h=0, lty=2)

o <- order(r.n.D1)
cm <- full.au$guild.member[o]
dr <- d.r[o]
i.c <- (1:nrow(full.au))[cm == "yes"]
i.c <- i.c[!is.na(i.c)]
i.p <- i.c - 1
i.p <- i.p[cm[i.p] == "no"]
i.n <- i.c + 1
i.n <- i.n[cm[i.n] == "no"]
(w <- wilcox.test(dr[i.c], c(dr[i.n],dr[i.p])))
boxplot(list(no=c(dr[i.p], dr[i.n]), yes=dr[i.c]), xlab="guild member",
				ylab="change in rank: number of D1 papers",
				main=paste("Wilcoxon p =", round(w$p.value, 4)))
abline(h=0, lty=2)

```

#### Correlates of being a strong component member

```{r RF-guilds, eval=FALSE}
library(randomForest)
ee.prod <- full.au[!is.na(full.au$guild.member),]
ee.RF <- randomForest(guild.member ~ ., ee.prod, importance=TRUE)
varImpPlot(ee.RF)
l.ee.prod <- as.data.frame(lapply(ee.prod[,-ncol(ee.prod)],
																	function(x) log10(x+1)))
l.ee.prod$betweenness <- betweenness(g.pubs)
l.ee.prod$strength <- strength(g.pubs)
l.ee.prod$closeness <- closeness(g.pubs)
l.ee.prod$degree <- degree(g.pubs)
l.ee.prod$guild.member <- ee.prod$guild.member
l.ee.RF <- randomForest(guild.member ~ ., l.ee.prod, importance=TRUE)
varImpPlot(l.ee.RF)
p.cl <- predict(l.ee.RF)
table(p.cl, l.ee.prod$guild.member)
partialPlot(l.ee.RF, l.ee.prod, "strength")
```


## Analyses the field of evolution, ecology and natural history

It seems that the field of evolution and ecology field is very fragmented, its authors belong to several components identified by the fast greedy algorithm. So we have to find a methods to get this field.

```{r evolecol}
i <- grepl("evol|ökol|zool|növé|hidrobio|etoló",
					 as.character(author.info$info), ignore.case=TRUE, perl=TRUE)
evoeco.au <- author.info[i,]
nrow(evoeco.au)
evoeco.prod <- sum.pubs[rownames(evoeco.au),]
```

We get the subraph for the field of evolution and ecology.

```{r evoeco-graph}
ee.g <- induced_subgraph(g.pubs, rownames(evoeco.au))
ee.g <- induced_subgraph(ee.g, names(V(ee.g)[strength(ee.g) > 0]))
comp.ee <- cluster_fast_greedy(ee.g)
memb.ee <- membership(comp.ee)
ml.ee <- tapply(names(memb.ee), memb.ee, unique)
coords <- layout_components(ee.g, layout_with_graphopt)
pdf(file="full-evoeco-map.pdf", width=20, height=20)
plot(ee.g, vertex.label.cex=0.01, edge.width=0.1, layout=coords)
dev.off()
```

### Strongly connected components

The next step is to identify the strongly connected components. We define strongly connected components as nodes connected with edges of weight more than 0.4. Hereafter, we refer these strongly connected components as _guilds_.

```{r hist-weights}
w.cut <- 0.4
w <- E(ee.g)$weight
hist(w, seq(0,1,0.01), main="", xlab="edge weight")
abline(v=w.cut, lty=2)
(p.cut <- sum(w >= 0.4)/length(w))
text(0.8, 800, paste(round(p.cut*100, 2), "% of edges", sep=""))
```

As the above histogram shows only a small proportion of edges have weights more than 0.4.

The following obtains these guilds.

```{r strong-comps}
ee.g.st.red <- subgraph.edges(ee.g, E(ee.g)[E(ee.g)$weight >= w.cut])
comp.red <- cluster_fast_greedy(ee.g.st.red)
memb.red <- membership(comp.red)
pdf(file="guids.pdf", width=10, height=10)
plot(ee.g.st.red, vertex.label.cex=0.75, edge.width=2, edge.color="black")
dev.off()
```

Some description of these components.

```{r descr-strong-comps}
t.memb.red <- table(memb.red)
length(t.memb.red)
vcount(ee.g.st.red)
vcount(ee.g.st.red)/vcount(ee.g)
(t.size.sc <- table(t.memb.red))
barplot(t.size.sc, xlab="size of guilds",
				ylab="frequency")
```

The above shows that most of these guilds contain two authors, but there are several components with at least four authors. About 17% of all authors take part in these components.

```{r plot-evoeco-guilds}
ee.g.st <- subgraph.edges(ee.g, E(ee.g)[E(ee.g)$weight > w.cut],
													delete.vertices=FALSE)
E(ee.g.st)$weight <- 1
pdf(file="full-evoeco-map-guilds.pdf", width=20, height=20)
plot(ee.g, vertex.label.cex=0.01, edge.width=0.1, layout=coords)
plot(ee.g.st, vertex.label.cex=0.01, edge.width=1, edge.color="red",
		 layout=coords, add=TRUE)
dev.off()
```

The guilds scattered all over the publication graph.

### Productivity of members of guilds

First we identify authors part of a guild in the productivity database.

```{r guild-ID}
guild.authors <- names(V(ee.g.st.red))
non.guild.authors <- names(V(ee.g))
non.guild.authors <- non.guild.authors[!(non.guild.authors %in%
																					 guild.authors)]
i <- rownames(evoeco.prod) %in% guild.authors
j <- rownames(evoeco.prod) %in% non.guild.authors

evoeco.prod$guild.member <- NA
evoeco.prod$guild.member[i] <- "yes"
evoeco.prod$guild.member[j] <- "no"
evoeco.prod$guild.member <- factor(evoeco.prod$guild.member)
```

```{r test-guild-member-prod}
(w.papers <- wilcox.test(n.papers ~ guild.member, evoeco.prod))
(wi.ec.papers <- wilcox.test(w.ec.papers ~ guild.member, evoeco.prod))
layout(matrix(1:2, ncol=2))
boxplot(n.papers ~ guild.member, evoeco.prod, log="y", xlab="guild member",
				ylab="number of papers",
				main=paste("Wilcoxon p = ", round(w.papers$p.value, 3)))
boxplot(I(w.ec.papers+1) ~ guild.member, evoeco.prod, log="y",
				xlab="guild member", ylab="weighted number of papers",
				main=paste("Wilcoxon p = ", round(wi.ec.papers$p.value, 3)))
layout(1)

(w.citations <- wilcox.test(n.citations ~ guild.member, evoeco.prod))
(wi.ec.citations <- wilcox.test(w.ec.citations ~ guild.member, evoeco.prod))
layout(matrix(1:2, ncol=2))
boxplot(I(n.citations+1) ~ guild.member, evoeco.prod, log="y",
				xlab="guild member", ylab="number of citations",
				main=paste("Wilcoxon p = ", round(w.citations$p.value, 3)))
boxplot(I(w.ec.citations+1) ~ guild.member, evoeco.prod, log="y",
				xlab="guild member", ylab="weighted number of citations",
				main=paste("Wilcoxon p = ", round(wi.ec.citations$p.value, 3)))
layout(1)

(w.D1 <- wilcox.test(n.D1 ~ guild.member, evoeco.prod))
(wi.ec.D1 <- wilcox.test(w.ec.D1 ~ guild.member, evoeco.prod))
layout(matrix(1:2, ncol=2))
boxplot(I(n.D1+1) ~ guild.member, evoeco.prod, log="y",
				xlab="guild member", ylab="number of D1 papers",
				main=paste("Wilcoxon p = ", round(w.D1$p.value, 3)))
boxplot(I(w.ec.D1+1) ~ guild.member, evoeco.prod, log="y",
				xlab="guild member", ylab="weighted number of D1 papers",
				main=paste("Wilcoxon p = ", round(wi.ec.D1$p.value, 3)))
layout(1)
```

Authors in guild are more affected by weighting productivity.

Next we investigate, how the authors rank changes if switch from unweighted to weighted publication measures.

```{r guild-ranks}
par(xpd=FALSE)
r.n.papers <- rank(evoeco.prod$n.papers)
r.flae.papers <- rank(evoeco.prod$w.flae.papers)
d.r <- r.flae.papers - r.n.papers
(w <- wilcox.test(d.r ~ guild.member, evoeco.prod))
boxplot(d.r ~ guild.member, evoeco.prod, xlab="guild member",
				ylab="change in rank: number of papers",
				main=paste("Wilcoxon p =", round(w$p.value, 3)))
abline(h=0, lty=2)

r.n.citations <- rank(evoeco.prod$n.citations)
r.flae.citations <- rank(evoeco.prod$w.flae.citations)
d.r <- r.flae.citations - r.n.citations
(w <- wilcox.test(d.r ~ guild.member, evoeco.prod))
boxplot(d.r ~ guild.member, evoeco.prod, xlab="guild member",
				ylab="change in rank: number of citations",
				main=paste("Wilcoxon p =", round(w$p.value, 4)))
abline(h=0, lty=2)

r.n.D1 <- rank(evoeco.prod$n.D1)
r.flae.D1 <- rank(evoeco.prod$w.flae.D1)
d.r <- r.flae.D1 - r.n.D1
(w <- wilcox.test(d.r ~ guild.member, evoeco.prod))
boxplot(d.r ~ guild.member, evoeco.prod, xlab="guild member",
				ylab="change in rank: number of D1 papers",
				main=paste("Wilcoxon p =", round(w$p.value, 4)))
abline(h=0, lty=2)
```

Here below, compare how the ranks of authors change when switching from unweighted to weighted measures, but now we compare authors of similar ranks.

```{r comp-similar-ranks}
o <- order(r.n.papers)
cm <- evoeco.prod$guild.member[o]
dr <- d.r[o]
i.c <- (1:nrow(evoeco.prod))[cm == "yes"]
i.c <- i.c[!is.na(i.c)]
i.p <- i.c - 1
i.p <- i.p[cm[i.p] == "no"]
i.n <- i.c + 1
i.n <- i.n[cm[i.n] == "no"]
(w <- wilcox.test(dr[i.c], c(dr[i.n],dr[i.p])))
boxplot(list(no=c(dr[i.p], dr[i.n]), yes=dr[i.c]), xlab="guild member",
				ylab="change in rank: number of papers",
				main=paste("Wilcoxon p =", round(w$p.value, 4)))
abline(h=0, lty=2)

o <- order(r.n.citations)
cm <- evoeco.prod$guild.member[o]
dr <- d.r[o]
i.c <- (1:nrow(evoeco.prod))[cm == "yes"]
i.c <- i.c[!is.na(i.c)]
i.p <- i.c - 1
i.p <- i.p[cm[i.p] == "no"]
i.n <- i.c + 1
i.n <- i.n[cm[i.n] == "no"]
(w <- wilcox.test(dr[i.c], c(dr[i.n],dr[i.p])))
boxplot(list(no=c(dr[i.p], dr[i.n]), yes=dr[i.c]), xlab="guild member",
				ylab="change in rank: number of citations",
				main=paste("Wilcoxon p =", round(w$p.value, 4)))
abline(h=0, lty=2)

o <- order(r.n.D1)
cm <- evoeco.prod$guild.member[o]
dr <- d.r[o]
i.c <- (1:nrow(evoeco.prod))[cm == "yes"]
i.c <- i.c[!is.na(i.c)]
i.p <- i.c - 1
i.p <- i.p[cm[i.p] == "no"]
i.n <- i.c + 1
i.n <- i.n[cm[i.n] == "no"]
(w <- wilcox.test(dr[i.c], c(dr[i.n],dr[i.p])))
boxplot(list(no=c(dr[i.p], dr[i.n]), yes=dr[i.c]), xlab="guild member",
				ylab="change in rank: number of D1 papers",
				main=paste("Wilcoxon p =", round(w$p.value, 4)))
abline(h=0, lty=2)

```

#### Correlates of being a strong component member

```{r RF-guilds, eval=FALSE}
library(randomForest)
ee.prod <- evoeco.prod[!is.na(evoeco.prod$guild.member),]
ee.RF <- randomForest(guild.member ~ ., ee.prod, importance=TRUE)
varImpPlot(ee.RF)
l.ee.prod <- as.data.frame(lapply(ee.prod[,-ncol(ee.prod)], function(x) log10(x+1)))
l.ee.prod$betweenness <- betweenness(ee.g)
l.ee.prod$strength <- strength(ee.g)
l.ee.prod$closeness <- closeness(ee.g)
l.ee.prod$guild.member <- ee.prod$guild.member
l.ee.RF <- randomForest(guild.member ~ ., l.ee.prod, importance=TRUE)
varImpPlot(l.ee.RF)
p.cl <- predict(l.ee.RF)
table(p.cl, l.ee.prod$guild.member)
partialPlot(l.ee.RF, l.ee.prod, "strength")
```

### Productivity of guilds

Next, we compare the productivity of guilds to that of 'guilds' compiled from random individuals. We define the following function to do the calculations.

The first measures the productivity of a guild, by counting (i) the number of unique papers produced by the guild as whole, `guild`, (ii) the sum of the number of papers authored by the guild members, `members`, and (iii) the sum of number of papers authored by the guild members, weighted by the equal contribution scheme, `members.weighted`. All three measures are divided by the number of members.

The second function generates `n.rep` guilds randomly compiled from authors not being member of any guilds and then calculates the above measures for each random guild.

The third function performs a randomisation test to see if the given measure for the focal guild differs from that of the random guilds.

The fourth function calculates the quantile of the guild measures relative to the distribution of random guild values.

```{r prod-fun}
guild.productivity <- function(guild, cikkek=papers.ls, szerzok=ee.prod) {
	p <- unique(unlist(sapply(cikkek[guild], function(y) y$id)))
	c(guild=length(p)/length(guild), members=mean(szerzok[guild, "n.papers"]),
		members.weighted=mean(szerzok[guild, "w.ec.papers"]))
}
rnd.guild.productivity <- function(guild.size, n.rep=1000, cikkek=papers.ls,
																		szerzok=ee.prod) {
	n.c.a <- rownames(szerzok)[szerzok$guild.member == "no"]
	res <- matrix(0, ncol=3, nrow=n.rep)
	for(i in 1:n.rep) {
		s <- sample(n.c.a, guild.size)
		r <- guild.productivity(s, cikkek=cikkek, szerzok=szerzok)
		res[i,] <- r
	}
	colnames(res) <- names(r)
	res
}
guild.productivity.test <- function(guild, p.value=0.05, cikkek=papers.ls,
																		szerzok=ee.prod) {
	res.g <- guild.productivity(guild, cikkek=cikkek, szerzok=szerzok)
	res.r <- rnd.guild.productivity(length(guild), 999, cikkek, szerzok)
	res.r <- rbind(res.g, res.r)
	value <- res.g
	l.crit <- numeric(ncol(res.r))
	u.crit <- numeric(ncol(res.r))
	for(i in 1:ncol(res.r)) {
		p <- quantile(res.r[,i], c(p.value/2, 1-p.value/2))
		l.crit[i] <- p[1]
		u.crit[i] <- p[2]
	}
	data.frame(value=res.g, l.crit=l.crit, u.crit=u.crit,
						 sig.mark=ifelse(l.crit < res.g & res.g < u.crit, "", "*"),
						 variable=names(res.g))
}
guild.productivity.q <- function(guild, p.value=0.05, n.rep=999,
																 cikkek=papers.ls, szerzok=ee.prod) {
	res.g <- guild.productivity(guild, cikkek=cikkek, szerzok=szerzok)
	res.r <- rnd.guild.productivity(length(guild), n.rep, cikkek, szerzok)
	res.r <- rbind(res.g, res.r)
	d <- numeric(ncol(res.r))
	m <- numeric(ncol(res.r))
	for(i in 1:ncol(res.r)) {
		d[i] <- sum(res.r[,i] > res.g[i])
		m[i] <- mean(res.r[,i])
	}
	data.frame(variable=names(res.g), value=res.g, rnd.mean=m,
						 quantile=d/nrow(res.r), guild.size=length(guild))
}
```

In the following we calculate the statistics for the guilds identified previously.

```{r guild-prod}
l.memb.red <- tapply(names(memb.red), memb.red, unique)
l <- sapply(l.memb.red, length)
i <- names(l.memb.red)[order(l, decreasing=TRUE)]
l.memb.red <- l.memb.red[i]
cl.p <- lapply(l.memb.red, guild.productivity.q)
cl.df <- data.frame()
for(n in names(cl.p)) {
	l <- cl.p[[n]]
	l$guild <- n
	rownames(l) <- NULL
	cl.df <- rbind(cl.df, l)
}
cl.df$sig <- ifelse(cl.df$quantile > 0.975 | cl.df$quantile < 0.025, "*", "")
cl.df$g2rnd <- cl.df$value/cl.df$rnd.mean
```

And finally, some analyses.

```{r analyse-guild-prod}
library(lme4)
library(emmeans)
m.all <- lmer(log10(g2rnd) ~ measure + (1|guild), cl.df)
drop1(m.all, test="Chisq")
summary(m.all)
(em <- emmeans(m.all, ~variable, type="response"))
pairs(em)
plot(em, horizontal=FALSE, xlab="measures", ylab="ratio of focal to random",
		 comparison=TRUE)
```

The result of the mixed effect model clearly shows that in guilds members achieve higher success if one considers success as the sum of the achievements documented individually than when one measures the composite productivity of the whole guild. Even using the weighted individual measures does not help this situation. This analyses were based on all guilds identified.

We now analyse only those guilds which show higher than random productivity on the basis of the unweighted individual measure.

```{r analyse-guild-prod-1}
i <- cl.df$variable == "members" & cl.df$g2rnd > 1
success.guilds <- as.character(cl.df$guild)[i]
i <- cl.df$guild %in% success.guilds
m.1 <- lmer(log10(g2rnd) ~ variable + (1|guild), cl.df, subset=i)
drop1(m.1, test="Chisq")
summary(m.1)
(em.1 <- emmeans(m.1, ~variable, type="response"))
pairs(em.1)
plot(em.1, horizontal=FALSE, xlab="measures", ylab="ratio of focal to random",
		 comparison=TRUE)
```

We arrived at the same conclusions; being part of a guild is advantageous if individual measures are considered.

# End matters

```{r session-info, include=TRUE, echo=TRUE, results="markup"}
sessionInfo()
```

<!-- vim: set foldmethod=syntax: -->
