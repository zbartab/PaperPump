---
title: Publication patterns in Evolution and Ecology
author: Zoltán Barta; Tibor Magura
date: !__DATE__
---

---
bibliography: /home/apa/notes/articles.bib
natbib: true
biblio-files: /home/apa/notes/articles.bib
biblio-style: /home/apa/lib/texinputs/AmNat
biblio-title: References
fontsize: 12pt
papersize: a4paper
include-before:
- \linenumbers
header-includes:
- \usepackage{lineno}
- \usepackage{double_spaced}
geometry:
- margin=1in
---

&define pub publication
&define pubnet publication network
&define colnet collaboration network
&define pubcart publication cartel
&define pubmat publication matrix
&define pubmats publication matrices
&define colmat collaboration matrix
&define colmats collaboration matrices
&define susgroup suspicious group

# TODOs

- calculate statistics for cut off values other than 0.4
	- plot the number of guilds, percentage of authors in guilds and percentage of edged affected as a function of the cut off value
- use the MTMT dataset to calculate cartels for different scientific fields
- implement calculation of strength
- description of the publication databases
	- fit power-law distributions

# Set up

Here we load some packages and custom codes.

```julia
## set the working directory
## load the libraries
using StatsBase, Statistics, PyPlot, Compose, Cairo
using LightGraphs, MetaGraphs, GraphPlot
using HypothesisTests
## load local code
include("CollaborationNetworks.jl")
include("PlotCollaborationNetworks.jl")
include("StatCollaborationNetworks.jl")
include("RandomPublicationNetworks.jl")
#include("ProcessMTMTrecords.jl")
#include("ProcessDBLPrecords.jl")
```

# Random networks

## Approaching real networks

We first load real networks.

```julia
MTMT = PubNet("MTMT/MTMTpubmat.mat")
rMTMT = PubNet("MTMT/MTMTpubmat-rewired-1.mat")


```

We plot some measures of the real and the randomly rewired networks.

```julia
figure()
subplot(2,2,1)
loglog(eCCDF2(MTMT.nauthors)..., label="real", ds="steps")
loglog(eCCDF2(rMTMT.nauthors)..., label="rand.", ds="steps")
#loglog(eCCDF2(genMTMT.nauthors)..., label="gen.", ds="steps")
#loglog(eCCDF2(rwgenMTMT.nauthors)..., label="rwgen.", ds="steps")
legend()
title("MTMT")
ylabel("ECCDF")
xlabel("number of authors per paper")
tight_layout()
subplot(2,2,2)
loglog(eCCDF2(MTMT.npapers)..., label="real", ds="steps")
loglog(eCCDF2(rMTMT.npapers)..., label="rand.", ds="steps")
#loglog(eCCDF2(genMTMT.npapers)..., label="gen.", ds="steps")
#loglog(eCCDF2(rwgenMTMT.npapers)..., label="rwgen.", ds="steps")
legend()
title("MTMT")
ylabel("ECCDF")
xlabel("number of papers per authors")
tight_layout()
subplot(2,2,3)
loglog(eCCDF2(MTMT.wpapers)..., label="real", ds="steps")
loglog(eCCDF2(rMTMT.wpapers)..., label="rand.", ds="steps")
#loglog(eCCDF2(genMTMT.wpapers)..., label="gen.", ds="steps")
#loglog(eCCDF2(rwgenMTMT.wpapers)..., label="rwgen.", ds="steps")
legend()
title("MTMT")
ylabel("ECCDF")
xlabel("weighted number of papers per authors")
tight_layout()
```

The two networks do not differ in terms of individual productivity, or author numbers.

```julia
figure()
#subplot(2,2,1)
loglog(eCCDF2(MTMT[:degree])..., ".-", label="real")
loglog(eCCDF2(rMTMT[:degree])..., ".-", label="rand.")
loglog(eCCDF2(genMTMT[:degree])..., ".-", label="gen.")
loglog(eCCDF2(rwgenMTMT[:degree])..., ".-", label="rwgen.")
loglog(eCCDF2(rsgenMTMT[:degree])..., ".-", label="rsgen.")
legend()
title("MTMT")
ylabel("ECCDF")
xlabel("degree")
tight_layout()
figure()
#subplot(2,2,2)
semilogy(eCCDF2(MTMT[:strength])..., ".-", label="real")
semilogy(eCCDF2(rMTMT[:strength])..., ".-", label="rand.")
semilogy(eCCDF2(genMTMT[:strength])..., ".-", label="gen.")
semilogy(eCCDF2(rwgenMTMT[:strength])..., ".-", label="rwgen.")
semilogy(eCCDF2(rsgenMTMT[:strength])..., ".-", label="rsgen.")
legend()
title("MTMT")
ylabel("ECCDF")
xlabel("strength")
tight_layout()
figure()
#subplot(2,2,3)
semilogy(eCCDF2(MTMT[:weights])..., ".-", label="real")
semilogy(eCCDF2(rMTMT[:weights])..., ".-", label="rand.")
semilogy(eCCDF2(genMTMT[:weights])..., ".-", label="gen.")
semilogy(eCCDF2(rwgenMTMT[:weights])..., ".-", label="rwgen.")
semilogy(eCCDF2(rsgenMTMT[:weights])..., ".-", label="rsgen.")
legend()
title("MTMT")
ylabel("ECCDF")
xlabel("weight")
tight_layout()
figure()
#subplot(2,2,4)
l = map(length, values(MTMT[:hierarchy][:lev2]))
loglog(eCCDF2(l)..., ".-", label="real")
l = map(length, values(rMTMT[:hierarchy][:lev2]))
loglog(eCCDF2(l)..., ".-", label="rand.")
l = map(length, values(genMTMT[:hierarchy][:lev2]))
loglog(eCCDF2(l)..., ".-", label="gen.")
l = map(length, values(rwgenMTMT[:hierarchy][:lev2]))
loglog(eCCDF2(l)..., ".-", label="rwgen.")
l = map(length, values(rsgenMTMT[:hierarchy][:lev2]))
loglog(eCCDF2(l)..., ".-", label="rsgen.")
legend()
title("MTMT")
ylabel("ECCDF")
xlabel("community size")
tight_layout()
figure()
#subplot(2,2,3)
loglog(eCCDF2(MTMT[:wpapers])..., ".-", label="real")
loglog(eCCDF2(rMTMT[:wpapers])..., ".-", label="rand.")
loglog(eCCDF2(genMTMT[:wpapers])..., ".-", label="gen.")
loglog(eCCDF2(rwgenMTMT[:wpapers])..., ".-", label="rwgen.")
loglog(eCCDF2(rsgenMTMT[:wpapers])..., ".-", label="rsgen.")
legend()
title("MTMT")
ylabel("ECCDF")
xlabel("number of papers")
tight_layout()
```


The two real networks differ substantially from their randomised counterparts. The real networks are less dense than the randomised ones, as their degree distributions indicate. On the other hand, the connections between nodes (authors) are much stronger than in randomised networks. In randomised networks no link with weight higher than 0.2 occurs, oppositely to real networks, where weights of around 1 is rather common.


```julia
dcreal = degreesdegrees(MTMT.puma)
h2dreal = fit(Histogram, dcreal)
dcrand = degreesdegrees(rMTMT.puma)
h2drand = fit(Histogram, dcrand)
figure(figsize=(8,4))
subplot(1,2,1)
x = collect(h2dreal.edges[1])
x = (x[1:(end-1)] + x[2:end])/2
y = collect(h2dreal.edges[2])
y = (y[1:(end-1)] + y[2:end])/2
pcolormesh(log10.(h2dreal.weights .+ 1), vmin=0, vmax=5)
title("real")
xlabel("number of papers")
ylabel("number of authors")
tight_layout()
subplot(1,2,2)
pcolormesh(log10.(h2drand.weights .+ 1), vmin=0, vmax=5)
title("rand.")
xlabel("number of papers")
ylabel("number of authors")
tight_layout()
```


# Generate random networks

```julia
carts = map(length, MTMT.cartels)
commsizes = map(length, values(MTMT.hierarchy[:lev1]))
rnets = Dict()
rnetscart = Dict()
for i in 1:10
	cs = expectedpapers(20, 80, 2.5, 10) # community sizes
	#cs = sample(commsizes, 500, replace=false)
	#cs = [200]
	k = saturatedexpectedpapers(Int(sum(cs)), 1000) # number of papers
	#k = sample(MTMT.npapers, Int(sum(cs)), replace=false)
	rpm = rndpubnet(k, 6.0, Int.(cs), nothing)
	rpm = rewire(rpm, 0.1)
	rpm3 = selectauthors(rpm, 3)
	rcm = collaborationmatrix(rpm3)
	rpubnet = PubNet(rpm, rcm, 0.4)
	rnets[i] = rpubnet
	rpm = rndpubnet(k, 6.0, Int.(cs), carts, 0.4)
	rpm = rewire(rpm, 0.1)
	rpm3 = selectauthors(rpm, 3)
	rcm = collaborationmatrix(rpm3)
	rpubnet = PubNet(rpm, rcm, 0.4)
	rnetscart[i] = rpubnet
	#graphplot(rpubnet.coga)
	#is_connected(rpubnet.coga)
end
figure()
for k in keys(rnets)
	loglog(eCCDF2(rnets[k].degrees)..., "-", alpha=0.25, color="blue", ds="steps")
end
for k in keys(rnetscart)
	loglog(eCCDF2(rnetscart[k].degrees)..., "-", alpha=0.25, color="green",
		ds="steps")
end
loglog(eCCDF2(MTMT.degrees)..., "-", color="red", label="real", ds="steps")
loglog(eCCDF2(rMTMT.degrees)..., "-", color="orange", label="real rewired",
	ds="steps")
legend()
title("MTMT")
xlabel("degree")
ylabel("eCCDF")
tight_layout()
figure()
for k in keys(rnets)
	semilogy(eCCDF2(rnets[k].strengthes)..., "-", alpha=0.25, color="blue",
		ds="steps")
end
for k in keys(rnetscart)
	semilogy(eCCDF2(rnetscart[k].strengthes)..., "-", alpha=0.25, color="green",
		ds="steps")
end
semilogy(eCCDF2(MTMT.strengthes)..., "-", color="red", label="real", ds="steps")
semilogy(eCCDF2(rMTMT.strengthes)..., "-", color="orange",
	label="real rewired", ds="steps")
legend()
title("MTMT")
xlabel("strength")
ylabel("eCCDF")
tight_layout()
figure()
for k in keys(rnets)
	semilogy(eCCDF2(rnets[k].weights)..., "-", alpha=0.25, color="blue",
		ds="steps")
end
for k in keys(rnetscart)
	semilogy(eCCDF2(rnetscart[k].weights)..., "-", alpha=0.25, color="green",
		ds="steps")
end
semilogy(eCCDF2(MTMT.weights)..., "-", color="red", label="real", ds="steps")
semilogy(eCCDF2(rMTMT.weights)..., "-", color="orange", label="real rewired",
	ds="steps")
legend()
title("MTMT")
xlabel("weight")
ylabel("eCCDF")
tight_layout()
figure()
for k in keys(rnets)
	semilogy(eCCDF2(rnets[k].clustcoefs)..., "-", alpha=0.25, color="blue",
		ds="steps")
end
for k in keys(rnetscart)
	semilogy(eCCDF2(rnetscart[k].clustcoefs)..., "-", alpha=0.25, color="green", ds="steps")
end
semilogy(eCCDF2(MTMT.clustcoefs)..., "-", color="red", label="real", ds="steps")
semilogy(eCCDF2(rMTMT.clustcoefs)..., "-", color="orange", label="real
	rewired", ds="steps")
legend()
title("MTMT")
xlabel("local clustering coefficient")
ylabel("eCCDF")
tight_layout()
```

## Cartels productivity

Simulated network:

```julia
cartprod = compareproductivity(rnetscart[10], rnetscart[10].cartels, 10)
cartprod = hcat(cartprod...)
figure()
for i in 1:size(cartprod, 1)
	semilogy(1:3, cartprod[i,:], alpha=0.1)
end
figure()
loglog(cartprod[:,1], cartprod[:,2], ".", alpha=0.2)
loglog([0.1,10], [0.1,10], ":")
xlabel("group productivity")
ylabel("mean number of papers")
tight_layout()
figure()
loglog(cartprod[:,1], cartprod[:,3], ".", alpha=0.2)
loglog([0.1,10], [0.1,10], ":")
xlabel("group productivity")
ylabel("mean weigthed number of papers")
tight_layout()
```



Real MTMT network:

```julia
cartprod = compareproductivity(MTMT, MTMT.cartels, 10)
cartprod = hcat(cartprod...)
figure()
for i in 1:size(cartprod, 1)
	semilogy(1:3, cartprod[i,:], alpha=0.1)
end
figure()
loglog(cartprod[:,1], cartprod[:,2], ".", alpha=0.2)
loglog([0.1,10], [0.1,10], ":")
xlabel("group productivity")
ylabel("mean number of papers")
tight_layout()
figure()
loglog(cartprod[:,1], cartprod[:,3], ".", alpha=0.2)
loglog([0.1,10], [0.1,10], ":")
xlabel("group productivity")
ylabel("mean weigthed number of papers")
tight_layout()
```



```julia
r = rndpubmat(MTMT[:puma], getauthorIDs(MTMT[:coga]), MTMT[:hierarchy][:lev1])
write_scimat("genMTMTpubmat.mat", r)
r = selectauthors(r, 3)
rcm = collaborationmatrix(r)
write_scimat("genMTMTcolmat.mat", rcm)
genMTMT = processpubnet("genMTMTpubmat.mat")
rgpm = rewire(genMTMT[:puma], 0.05)
write_scimat("rwgMTMTpubmat.mat", rgpm)
rgcm = collaborationmatrix(rgpm)
write_scimat("rwgMTMTcolmat.mat", rgcm)
rwgenMTMT = processpubnet("rwgMTMTpubmat.mat")
rgpm = reshuffle(genMTMT[:puma], 1000)
write_scimat("rsgMTMTpubmat.mat", rgpm)
rgcm = collaborationmatrix(rgpm)
write_scimat("rsgMTMTcolmat.mat", rgcm)
rsgenMTMT = processpubnet("rsgMTMTpubmat.mat")

```


```julia
l = map(length, values(MTMT[:hierarchy][:lev1]))
s = size(MTMT[:puma])
pr = s[1]/s[2]
k = authornumbers(MTMT[:puma])
r = rndpubnet(k, pr, l)
write_scimat("rMTMTpubmat.mat", r)
rcm = collaborationmatrix(r)
write_scimat("rMTMTcolmat.mat", rcm)
genMTMT = processpubnet("rMTMTpubmat.mat")
rgpm = rewire(genMTMT[:puma], 5.0)
write_scimat("rwgMTMTpubmat.mat", rgpm)
rgcm = collaborationmatrix(rgpm)
write_scimat("rwgMTMTcolmat.mat", rgcm)
rwgenMTMT = processpubnet("rwgMTMTpubmat.mat")
```


The correlation between degree of nodes (authors) and the number of papers an author wrote for all nodes and for strongly connected nodes.


```julia
d = degree(MTMT[:coga])
ids = getauthorIDs(MTMT[:coga])
inds = getauthorindex(MTMT[:puma], ids)
np = papernumbers(MTMT[:puma])
np = np[inds]
c_off = 0.5
MTMT[:strongs] = subnet(MTMT[:coga], c_off)
a = getauthorIDs(MTMT[:strongs])
istMTMT = getauthorindex(MTMT[:coma], a)
figure()
semilogy(d, np, ".", label="all nodes", alpha=0.5)
semilogy(d[istMTMT], np[istMTMT], ".", label="strong nodes", alpha=0.5)
legend()
xlabel("degrees")
ylabel("number of papers")
title("MTMT")
tight_layout()
```

Strongly connected nodes tend to have lower degrees.


```julia
r = 0:100:400
t = fit(Histogram, d, r)
ts = fit(Histogram, d[istMTMT], r)
figure()
x = (r[1:(end-1)] .+ r[2:end]) ./ 2.0
bar(x, ts.:weights ./ t.:weights)
title("MTMT")
xlabel("degree")
ylabel("proportion of strong nodes")
tight_layout()
```


The correlation between strength of nodes (authors) and the number of papers an author wrote for all nodes and for strongly connected nodes.


```julia
d = strength(MTMT[:coma])
figure()
semilogy(d, np, ".", label="all nodes", alpha=0.5)
semilogy(d[istMTMT], np[istMTMT], ".", label="strong nodes", alpha=0.5)
legend()
xlabel("strength")
ylabel("number of papers")
title("MTMT")
tight_layout()
```

Strongly connected nodes tend to have higher strength.

```julia
r = 0:1:7
t = fit(Histogram, d, r)
ts = fit(Histogram, d[istMTMT], r)
figure()
x = (r[1:(end-1)] .+ r[2:end]) ./ 2.0
bar(x, ts.:weights ./ t.:weights)
title("MTMT")
xlabel("strength")
ylabel("proportion of strong nodes")
tight_layout()
```


## Modularity

We calculate local clustering coefficients for the real networks and their randomised counterparts. According to [Barabási's book](http://networksciencebook.com/chapter/9#hierarchical), the relation between local clustering coefficients and the nodes' degrees should be linear on a log-log plot, i.e. local clustering coefficients should decrease with degrees.

First, we calculate the local clustering coefficients.

```julia
lcMTMT = local_clustering_coefficient(MTMT[:coga])
lcdblp = local_clustering_coefficient(dblp[:coga])
rlcMTMT = local_clustering_coefficient(rMTMT[:coga])
rlcdblp = local_clustering_coefficient(rdblp[:coga])
```

We also obtain the strongly connected nodes to see how these nodes are placed in the following plots. (Note, randomised nets do not have strongly connected nodes.)

```julia
c_off = 0.7
MTMT[:strongs] = subnet(MTMT[:coga], c_off)
dblp[:strongs] = subnet(dblp[:coga], c_off)
a = getauthorIDs(MTMT[:strongs])
istMTMT = getauthorindex(MTMT[:coma], a)
a = getauthorIDs(dblp[:strongs])
istdblp = getauthorindex(dblp[:coma], a)
```


Next, the distributions of the local clustering coefficients.

```julia
figure()
semilogy(eCCDF(lcMTMT)..., ".-", label="MTMT")
semilogy(eCCDF(lcdblp)..., ".-", label="dblp")
semilogy(eCCDF(rlcMTMT)..., ".-", label="rand MTMT")
semilogy(eCCDF(rlcdblp)..., ".-", label="rand dblp")
legend()
xlabel("local clustering coefficients")
ylabel("CCDF")
tight_layout()
```

According to this plot, nodes in the real networks have high clustering coefficients more frequently than nodes in randomised counterparts.

Then the log-log plots between degrees and local clustering coefficients.

```julia
figure(figsize=(8,4.5))
subplot(2,2,1)
loglog(dMTMT, lcMTMT, ".", label="MTMT", alpha=0.01)
loglog(dMTMT[istMTMT], lcMTMT[istMTMT], ".", label="strong MTMT")
legend()
xlabel(L"degrees, $k$")
ylabel(L"$C(k)$")
subplot(2,2,2)
loglog(ddblp, lcdblp, ".", label="dblp", alpha=0.01)
loglog(ddblp[istdblp], lcdblp[istdblp], ".", label="strong dblp")
legend()
xlabel(L"degrees, $k$")
ylabel(L"$C(k)$")
subplot(2,2,3)
loglog(rdMTMT, rlcMTMT, ".", label="rand MTMT", alpha=0.01)
legend()
xlabel(L"degrees, $k$")
ylabel(L"$C(k)$")
subplot(2,2,4)
loglog(rddblp, rlcdblp, ".", label="rand dblp", alpha=0.01)
legend()
xlabel(L"degrees, $k$")
ylabel(L"$C(k)$")
tight_layout()
```

According to the above plots, there is a decreasing relationship between nodes' degree and local clustering coefficients. This suggests a hierarchical structure in each network. The interesting point is that the randomised networks also have a decreasing relationship, but the [Figure 9.14 in Barabási's book](http://networksciencebook.com/#figure-9-14) suggests that random rewiring a hierarchical network should lead a constant relationship. Note, however, we randomly rewire here the publication networks and not the collaboration networks. Nevertheless, the distribution of local clustering coefficients suggest that community structure of randomised networks is not so obvious.

The nodes being part of strongly connected components spread all over the space occupied by other nodes in the degree vs local clustering components plane. They seem to aggregate towards higher clustering coefficients, but this pattern is not very obvious in the MTMT dataset.

```julia
sMTMT = strength(MTMT[:coma])
sdblp = strength(dblp[:coma])
rsMTMT = strength(rMTMT[:coma])
rsdblp = strength(rdblp[:coma])
```

```julia
figure(figsize=(8,4.5))
subplot(2,2,1)
loglog(sMTMT, lcMTMT, ".", label="MTMT", alpha=0.05)
loglog(sMTMT[istMTMT], lcMTMT[istMTMT], ".", label="strong MTMT")
legend()
xlabel("strength")
ylabel(L"$C(k)$")
subplot(2,2,2)
loglog(sdblp, lcdblp, ".", label="dblp", alpha=0.05)
loglog(sdblp[istdblp], lcdblp[istdblp], ".", label="strong dblp")
legend()
xlabel("strength")
ylabel(L"$C(k)$")
subplot(2,2,3)
loglog(rsMTMT, rlcMTMT, ".", label="rand MTMT", alpha=0.05)
legend()
xlabel("strength")
ylabel(L"$C(k)$")
subplot(2,2,4)
loglog(rsdblp, rlcdblp, ".", label="rand dblp", alpha=0.05)
legend()
xlabel("strength")
ylabel(L"$C(k)$")
tight_layout()
```

There is no strong relationship between the local clustering coefficient of a node and its strength, with the exception of the randomised MTMT dataset. Strongly connected nodes tend to have high strength and high local clustering coefficient.

```julia
figure(figsize=(8,4.5))
subplot(2,2,1)
loglog(sMTMT ./ dMTMT, lcMTMT, ".", label="MTMT", alpha=0.05)
loglog(sMTMT[istMTMT] ./ dMTMT[istMTMT], lcMTMT[istMTMT], ".", 
		label="strong MTMT")
legend()
xlabel("average strength")
ylabel(L"$C(k)$")
subplot(2,2,2)
loglog(sdblp ./ ddblp, lcdblp, ".", label="dblp", alpha=0.05)
loglog(sdblp[istdblp] ./ ddblp[istdblp], lcdblp[istdblp], ".", 
		label="strong dblp")
legend()
xlabel("average strength")
ylabel(L"$C(k)$")
subplot(2,2,3)
loglog(rsMTMT ./ rdMTMT, rlcMTMT, ".", label="rand MTMT", alpha=0.05)
legend()
xlabel("average strength")
ylabel(L"$C(k)$")
subplot(2,2,4)
loglog(rsdblp ./ rddblp, rlcdblp, ".", label="rand dblp", alpha=0.05)
legend()
xlabel("average strength")
ylabel(L"$C(k)$")
tight_layout()
```

There is clear positive relationship between local clustering coefficient and average strength of nodes. Nodes with strong links tends to be cluster at high clustering coefficient and large strength values. Note, however, that for a given strength, strongly connected nodes have rather low local clustering coefficients.

```julia
figure(figsize=(8,4.5))
subplot(2,2,1)
loglog(sMTMT, dMTMT, ".", label="MTMT", alpha=0.1)
loglog(sMTMT[istMTMT], dMTMT[istMTMT], ".", label="strong MTMT")
legend()
xlabel("stregth")
ylabel("degree")
subplot(2,2,2)
loglog(sdblp, ddblp, ".", label="dblp", alpha=0.1)
loglog(sdblp[istdblp], ddblp[istdblp], ".", label="strong dblp")
legend()
xlabel("stregth")
ylabel("degree")
subplot(2,2,3)
loglog(rsMTMT, rdMTMT, ".", label="MTMT")
legend()
xlabel("stregth")
ylabel("degree")
subplot(2,2,4)
loglog(rsdblp, rddblp, ".", label="dblp")
legend()
xlabel("stregth")
ylabel("degree")
tight_layout()
```

Not surprisingly, nodes of high strength have many connections (high degree). The strongly connected nodes are restricted to have high strength and relatively low degree.

## Hierarchy

Plotting the communities.

```julia
H = read_louvain_tree("MTMT/MTMTcolmat.tree")
for i in keys(H[:lev2])
	fn = string("MTMT-comm-", i, "-graph.pdf")
	g = MTMT[:coga][H[:lev2][i]]
	nv(g) > 1 && graphplot(g, spring_layout(g, C=10)...; filename=fn)
end
```

Calculating statistics for communities.


```julia
npapers = papernumbers(MTMT.puma)
wpapers = weightedpapers(MTMT.puma)
key = Int[]
p_strongnodes = Float64[]
p_strongedges = Float64[]
nnodes = Float64[]
nedges = Float64[]
mWeights = Float64[]
sdWeights = Float64[]
mdegrees = Float64[]
sddegrees = Float64[]
m_npapers = Float64[]
sd_npapers = Float64[]
m_wpapers = Float64[]
sd_wpapers = Float64[]
for i in keys(MTMT.hierarchy[:lev1])
	members = MTMT.hierarchy[:lev1][i]
	g = MTMT.coga[members]
	nv(g) <= 1 && continue
	push!(key, i)
	d = describecartels(g)
	push!(p_strongnodes, d["cartel_nodes"]/d["no_nodes"])
	push!(p_strongedges, d["no_strongedges"]/d["no_edges"])
	W = Weights(g)
	push!(mWeights, mean(W))
	push!(sdWeights, std(W))
	dg = degree(g)
	push!(mdegrees, mean(dg))
	push!(sddegrees, std(dg))
	push!(nnodes, nv(g))
	push!(nedges, ne(g))
	np = npapers[members]
	push!(m_npapers, mean(np))
	push!(sd_npapers, std(np))
	wp = wpapers[members]
	push!(m_wpapers, mean(wp))
	push!(sd_wpapers, std(wp))
end
c_df = DataFrame(key = key, nnodes = nnodes, nedges = nedges, p_strnodes =
	p_strongnodes, p_stredges = p_strongedges, mWeights = mWeights, sdWeights =
	sdWeights, mdegrees = mdegrees, sddegrees = sddegrees, m_npapers = m_npapers,
	sd_npapers = sd_npapers, m_wpapers = m_wpapers, sd_wpapers = sd_wpapers)
```


```julia
n = names(c_df)
for i in 1:(length(n)-1)
	for j in (i+1):length(n)
		figure()
		scatter(c_df[!, n[i]], c_df[!, n[j]])
		xlabel(string(n[i]))
		ylabel(string(n[j]))
		tight_layout()
	end
end
```


```julia
p_rewire = [0.0, 0.01, 0.05, 0.1, 0.25]
Qs = []
mats = []
for p in p_rewire
	Q, rw = rewire_communities(MTMT[:puma], H[:lev2], p, "MTMT-comm-rewire")
	push!(Qs, Q)
	push!(mats, rw)
end
```

```julia
figure()
for i in 1:length(p_rewire)
	W = Weights(mats[i][:coga])
	semilogy(eCCDF2(W)..., "-", label="p_rw = $(p_rewire[i])")
end
legend()
xlabel("weights")
ylabel("eCCDF")
tight_layout()
```

```julia
figure()
for i in 1:length(p_rewire)
	W = degree(mats[i][:coga])
	loglog(eCCDF2(W[W .> 0])..., "-", label="p_rw = $(p_rewire[i])")
end
legend()
xlabel("degrees")
ylabel("eCCDF")
tight_layout()
```

```julia
figure()
for i in 1:length(p_rewire)
	W = strength(mats[i][:coma])
	semilogy(eCCDF2(W)..., "-", label="p_rw = $(p_rewire[i])")
end
legend()
xlabel("strength")
ylabel("eCCDF")
tight_layout()
```

```julia
figure()
plot(p_rewire, Qs, ".-")
ylim(-0.05, 1.05)
xlabel("proportion rewired")
ylabel("modularity, Q")
tight_layout()
```


```julia
MTMT[:bjd] = degreedegreecor(MTMT[:puma])
MTMT[:gpuma] = generaterndbipartite(MTMT[:bjd])
while sum(MTMT[:gpuma] .> 1) > 0
	simplifybipartite!(MTMT[:gpuma])
end
MTMT[:gpuma] = generate_publicationmatrix(MTMT[:gpuma])
g_MTMT3 = selectauthors(MTMT[:gpuma], 3)
MTMT[:gcoma] = collaborationmatrix(g_MTMT3)
MTMT[:gcoga] = collaborationgraph(MTMT[:gcoma])
```


```julia
rW = Weights(MTMT[:gcoga])
rd = degree(MTMT[:gcoga])
figure()
semilogy(eCCDF2(wMTMT)..., "-", label="real")
semilogy(eCCDF2(rwMTMT)..., "-", label="rand")
semilogy(eCCDF2(rW)..., "-", label="rand commun. 0.1")
legend()
ylabel("ECCDF")
xlabel("weight")
title("MTMT")
tight_layout()
figure()
semilogy(eCCDF2(dMTMT)..., "-", label="real")
semilogy(eCCDF2(rdMTMT)..., "-", label="rand")
semilogy(eCCDF2(rd)..., "-", label="rand commun.")
legend()
ylabel("ECCDF")
xlabel("degree")
title("MTMT")
tight_layout()
```

```julia

```




## Productivity of members vs non-members

MTMT dataset:

```julia
c_off = 0.4
MTMT[:strongs] = subnet(MTMT[:coga], c_off)
a = papernumbers(MTMT[:puma])
id_cm = getauthorIDs(MTMT[:strongs])
id_all = getauthorIDs(MTMT[:coga])
in_cm = getauthorindex(MTMT[:puma], id_cm)
in_all = getauthorindex(MTMT[:puma], id_all)
in_nm = setdiff(in_all, in_cm)
figure()
for i in 1:20
	inm = sample(in_nm, length(in_cm), replace=false)
	loglog(eCCDF(a[inm])..., ".-", color="lightgray")
end
loglog(eCCDF(a[in_cm])..., ".-", label="cartel members")
legend()
xlabel("papers per author")
ylabel("CCDF")
title("MTMT dataset")
tight_layout()
```

dblp dataset:

```julia
c_off = 0.4
dblp[:strongs] = subnet(dblp[:coga], c_off)
a = papernumbers(dblp[:puma])
id_cm = getauthorIDs(dblp[:strongs])
id_all = getauthorIDs(dblp[:coga])
in_cm = getauthorindex(dblp[:puma], id_cm)
in_all = getauthorindex(dblp[:puma], id_all)
in_nm = setdiff(in_all, in_cm)
figure()
for i in 1:20
	inm = sample(in_nm, length(in_cm), replace=false)
	loglog(eCCDF(a[inm])..., ".-", color="lightgray")
end
loglog(eCCDF(a[in_cm])..., ".-", label="cartel members")
legend()
xlabel("papers per author")
ylabel("CCDF")
title("dblp dataset")
tight_layout()
```

```julia
c_off = 0.4
#MTMT[:strongs] = subnet(MTMT[:coga], c_off)
wp = weightedpapers(MTMT[:puma])
id_cm = getauthorIDs(MTMT[:strongs])
id_all = getauthorIDs(MTMT[:coga])
in_cm = getauthorindex(MTMT[:puma], id_cm)
in_all = getauthorindex(MTMT[:puma], id_all)
in_nm = setdiff(in_all, in_cm)
figure()
for i in 1:20
	inm = sample(in_nm, length(in_cm), replace=false)
	loglog(eCCDF(wp[inm])..., ".-", color="lightgray")
end
loglog(eCCDF(wp[in_cm])..., ".-", label="cartel members")
legend()
xlabel("weighted papers per author")
ylabel("CCDF")
title("MTMT dataset")
tight_layout()
```

```julia
c_off = 0.4
#dblp[:strongs] = subnet(dblp[:coga], c_off)
wp = weightedpapers(dblp[:puma])
id_cm = getauthorIDs(dblp[:strongs])
id_all = getauthorIDs(dblp[:coga])
in_cm = getauthorindex(dblp[:puma], id_cm)
in_all = getauthorindex(dblp[:puma], id_all)
in_nm = setdiff(in_all, in_cm)
figure()
for i in 1:20
	inm = sample(in_nm, length(in_cm), replace=false)
	loglog(eCCDF(wp[inm])..., ".-", color="lightgray")
end
loglog(eCCDF(wp[in_cm])..., ".-", label="cartel members")
legend()
xlabel("weighted papers per author")
ylabel("CCDF")
title("dblp dataset")
tight_layout()
```


## Illustrating cartels

### Authors with equal productivity

We generate a random publication network where all authors produce three papers. Then we create a cartel by that five author invite each others to be a coauthor on each others papers.

```julia
#k2 = repeat([3], 30)
#k2 = collect(1:30) .^ 2
k2 = collect(1:30)
cartel = collect([1,2,3,29,30])
noncartel = setdiff(1:length(k2), cartel)
pnnc, pnwc = generate_rndnet(k2, 1000, cartel, 1.0)
psnc =pubnetstats(pnnc)
pswc =pubnetstats(pnwc)
```

We next analyse, how forming cartels influence the authors publication productivity. First, we calculate several measures for the nodes (authors).

The formation of cartel increases the productivity of its all members. Note, however, that the most productive members' productivity increases less. If the productivity of cartel members are very different then the highly productive members are actually lost in productivity on becoming members iff we use weighted paper numbers as measure of productivity. This suggests that cartels should be formed by authors of similar productivity given that weighted paper numbers is used for ranking authors.

TODO: investigate, how ranking of authors changes by becoming cartel members.


```julia
close("all")
figure(figsize=(12,8))
subplot(2,3,1)
plotcartelseffects(psnc, pswc, :npapers, mytitle="number of papers")
subplot(2,3,4)
plotcartelseffects(psnc, pswc, :npapers, f=ordinalrank, mytitle="rank of number of papers")
subplot(2,3,2)
plotcartelseffects(psnc, pswc, :wpapers, mytitle="weighted papers")
subplot(2,3,5)
plotcartelseffects(psnc, pswc, :wpapers, f=ordinalrank, mytitle="rank of weighted papers")
subplot(2,3,3)
hist(psnc[:weights], 0:0.05:1)
hist(pswc[:weights], 0:0.05:1, alpha=0.5)
title("weights")
tight_layout()
```


```julia
b = hcat(psnc[:npapers][cartel], pswc[:npapers][cartel])
b[:,2] ./ b[:,1]
a = hcat(psnc[:wpapers][cartel], pswc[:wpapers][cartel])
r = a[:,2] ./ a[:,1]
```

The productivity of non-members of the cartel decreases in almost all cases, if we count the weighted paper numbers. If we count simply the full number of papers their productivity remained unchanged. This indicates, that even using the weighted paper numbers as measure productivity does not correct for forming cartels it does decrease the productivity of collaborators' productivity giving rise to a conflict of interest between members and non-members of cartels which may results in a resistance of non-members to collaborate with cartel members.

```julia
b = hcat(psnc[:npapers][noncartel], pswc[:npapers][noncartel])
b[:,2] ./ b[:,1]
a = hcat(psnc[:wpapers][noncartel], pswc[:wpapers][noncartel])
a[:,2] ./ a[:,1]
```

```julia
b = hcat(psnc[:degree][cartel], pswc[:degree][cartel])
b[:,2] ./ b[:,1]
b = hcat(psnc[:degree][noncartel], pswc[:degree][noncartel])
b[:,2] ./ b[:,1]
```

The effect of random rewiring the !pubmats.

```julia
#pnnc, pnwc = generate_rndnet(collect(1:30), 500, [1,2,3,29,30], 0.9)
k = saturatedexpectedpapers(1000)
pnnc, pnwc = generate_rndnet(k, 100000, [1,2,3,29,30], 0.9)
Wnc = Weights(pnnc[:coga])
Wwc = Weights(pnwc[:coga])
close("all");
figure(figsize=(8,4.5));
subplot(2,2,2);
for i in 1:10
	rpnwc = rewire(pnwc, 100000)
	semilogy(eCCDF(Weights(rpnwc[:coga]))..., label="", color="gray", alpha=0.10);
end
semilogy(eCCDF(Wwc)..., ".-", label="with cartel");
xlim(-0.05,1.05)
yl = ylim()
#legend();
title("cartels added")
#xlabel("weights")
ylabel("CCDF")
subplot(2,2,1);
for i in 1:10
	rpnnc = rewire(pnnc, 100000)
	semilogy(eCCDF(Weights(rpnnc[:coga]))..., label="", color="gray", alpha=0.10);
end
semilogy(eCCDF(Wnc)..., ".-", label="no cartels");
xlim(-0.05,1.05)
ylim(yl)
#legend();
title("no cartels added")
#xlabel("weights")
ylabel("CCDF")
subplot(2,2,3)
hist(Wnc, 0:0.1:1)
xlim(-0.05,1.05)
xlabel("weights")
ylabel("frequency")
#title("no cartels added")
subplot(2,2,4)
hist(Wwc, 0:0.1:1)
xlim(-0.05,1.05)
ylabel("frequency")
xlabel("weights")
#title("cartels added")
tight_layout();
describecartels(pnnc[:coga])
describecartels(rpnnc[:coga])
describecartels(pnwc[:coga])
describecartels(rpnwc[:coga])

```

```julia
#wM = Weights(colnets[:MTMT])
#wd = Weights(colnets[:dblp])
#rwM = Weights(rcolnet[:MTMT1])
#rwd = Weights(rcolnet[:dblp1])
#k = round.(collect(1:300) .^ 1.2)
k = saturatedexpectedpapers(100)
#k = repeat([3], 50)
csizes = Dict(2 => 10, 3 => 8, 4 => 3, 5 => 2, 6 => 1)
cartels = generate_cartels(100, csizes)
pnnc, pnwc = generate_rndnet(k, 10000, cartels, 0.5)
rpnnc_1 = rewire(pnnc, 100000)
rpnwc_1 = rewire(pnwc, 100000)
rpnnc_2 = rewire(pnnc, 100000)
rpnwc_2 = rewire(pnwc, 100000)
close("all");
figure(figsize=(8,4.5));
#subplot(1,2,1);
semilogy(eCCDF(Weights(pnnc[:coga]))..., label="no cartel");
semilogy(eCCDF(Weights(rpnnc_1[:coga]))..., label="random1, no cartel");
semilogy(eCCDF(Weights(rpnnc_2[:coga]))..., label="random2, no cartel");
#legend();
#subplot(1,2,2);
semilogy(eCCDF(Weights(pnwc[:coga]))..., label="with cartel");
semilogy(eCCDF(Weights(rpnwc_1[:coga]))..., label="random1, with cartel");
semilogy(eCCDF(Weights(rpnwc_2[:coga]))..., label="random2, with cartel");
semilogy(eCCDF(wM)..., label="MTMT");
semilogy(eCCDF(rwM)..., label="random MTMT");
semilogy(eCCDF(wd)..., label="dblp");
semilogy(eCCDF(rwd)..., label="random dblp");
xlabel("weights")
ylabel("survival function")
legend(ncol=2);
tight_layout();

figure(figsize=(8,4));
loglog(eCCDF(degree(pnnc[:coga]))..., label="no cartel");
loglog(eCCDF(degree(rpnnc_1[:coga]))..., label="random1, no cartel");
loglog(eCCDF(degree(rpnnc_2[:coga]))..., label="random2, no cartel");
loglog(eCCDF(degree(pnwc[:coga]))..., label="with cartel");
loglog(eCCDF(degree(rpnwc_1[:coga]))..., label="random1, with cartel");
loglog(eCCDF(degree(rpnwc_2[:coga]))..., label="random2, with cartel");
loglog(eCCDF(degree(colnets[:MTMT]))..., label="MTMT");
loglog(eCCDF(degree(rcolnet[:MTMT1]))..., label="random, MTMT");
loglog(eCCDF(degree(colnets[:dblp]))..., label="dblp");
loglog(eCCDF(degree(rcolnet[:dblp1]))..., label="random, dblp");
xlabel("degree")
ylabel("survival function")
legend(ncol=2);
tight_layout()

describecartels(pnnc[:coga])
describecartels(rpnnc_1[:coga])
describecartels(rpnnc_2[:coga])
describecartels(pnwc[:coga])
describecartels(rpnwc_1[:coga])
describecartels(rpnwc_2[:coga])

```


We create a random network with parameters similar to real datasets.

```julia
close("all")
fig = figure(figsize=(8,4.75))
k_rand = saturatedexpectedpapers(500, 1000000)
ks = sortperm(k_rand)
subplot(2,2,1)
plotloglog(k_rand, "", "Number of papers per authors")
r_puma = generate_publicationmatrix(k_rand, 10000)
r_coma = collaborationmatrix(r_puma)
r_coga = collaborationgraph(r_coma)
r_puma_c = deepcopy(r_puma)
cartel = collect(Iterators.flatten([ks[1:3],ks[(end-1):end]])) # cartels from mixed productivity authors
#cartel = ks[1:5] # cartels from low productivity authors
#cartel = ks[(end-4):end] # cartels from high productivity authors
addcartel!(r_puma_c, cartel, 1.0)
r_coma_c = collaborationmatrix(r_puma_c)
r_coga_c = collaborationgraph(r_coma_c)
lx, ly = spring_layout(r_coga_c, C=20)
graphplot(r_coga_c, lx, ly, filename="rand_g_cart")
graphplot(r_coga, lx, ly, filename="rand_g")
npn = papernumbers(r_puma)
npc = papernumbers(r_puma_c)
npwn = weightedpapers(r_puma)
npwc = weightedpapers(r_puma_c)
subplot(2,2,2)
for i in cartel
	plot([1,2], [npn[i], npc[i]])
	plot([3,4], [npwn[i], npwc[i]])
end
subplot(2,2,3)
plotloglog(degree(r_coga), "no cartel")
plotloglog(degree(r_coga_c), "with cartel")
subplot(2,2,4)
xn, yn = eCCDF(Weights(r_coga))
xc, yc = eCCDF(Weights(r_coga_c))
plot(xn, yn, label="no cartel")
plot(xc, yc, label="with cartel")
legend()
tight_layout()
hcat(weightedpapers(r_puma)[cartel], papernumbers(r_puma)[cartel],
			weightedpapers(r_puma_c)[cartel], papernumbers(r_puma_c)[cartel])
```


# The datasets

&define mtmt __MTMT__
&define dblp __dblp__

TODO: clarify description of data sources

We use several publication database to investigate possible publication cartels. After downloading publication records we collected for each authors for whom we have data the papers the given author contributed to. From these data we construct a !pubmat, _M_, where rows represent papers while columns represent authors. The _m_~i,j~ element of _M_ gives if author _j_ contributed to paper _i_ (_m_~i,j~ = 1) or not (_m_~i,j~ = 0). Basically, _M_ represents a bipartite graph with authors and papers being the two types of nodes. From the !pubmat we constructed a weighted !colmat by projecting the bipartite matrix to the authors. The weight in the !colmat between author _i_ and _j_ represents the proportion of shared publications, $p_{i,j}$: 

$$
p_{i,j} = \frac{|A_i \cap A_j|}{|A_i \cup A_j|}
$$

Here, _A_~i~ is the set of papers to which author _i_ contributed. In other words, the weight between two authors is the number of shared papers divided by the total number of unique papers to which either of authors _i_ and _j_ contributed to. This weight is also called as Jaccard similarity. It varies between zero (i.e. no common publication between author _i_ and _j_) and one (i.e. all publication by the two authors are shared). Finally, we transformed the !colmats to weighted undirected !colnets.

The first database is the Hungarian bibliographic database, [!mtmt](https://www.mtmt.hu). Obtaining data from !mtmt is described in the [first attempt](publication_patterns.Rmd) of analysing !pubcarts. 
The details of processing !mtmt data is organised and documented in a [Makefile](MTMT/Makefile).

The other database is [dblp](https://dblp.org), which is a computer science bibliography database. The details of obtaining and processing !dblp data is documented in a [Makefile](dblp/Makefile).

The !dblp datasets contain many authors who have only one paper in the database. Having those authors can distort the collaboration relationship because all those authors who have only one paper in the dataset but their share that paper will have a very strong weight. To reduce this distortion we remove those authors from the !pubmat who have only three or less papers when we produced the !colmat. To be consistent we also filtered these authors out from the !mtmt database. All computation on !colmats are based on !colmats produced from these reduced !pubmats.

Here we load and process the available datasets and produce !pubmats, !colmats and !colnets. We store these matrices and graphs in dictionaries for latter processing.

```julia
pubmats = Dict()
colmats = Dict()
colnets = Dict()
pubmats[:MTMT] = read_scimat("MTMT/MTMTpubmat.mat")
colmats[:MTMT] = read_scimat("MTMT/MTMTcolmat.mat")
colnets[:MTMT] = collaborationgraph(colmats[:MTMT])
pubmats[:dblp] = read_scimat("dblp/dblppubmat.mat")
colmats[:dblp] = read_scimat("dblp/dblpcolmat.mat")
colnets[:dblp] = collaborationgraph(colmats[:dblp])
```

# Analyses of the publication and collaboration networks

## Description of the !pub dataset

The distribution of the number of papers contributed to by an author.

```julia
for k in keys(pubmats)
	no_papers = papernumbers(pubmats[k])
	onepaperers = sum(no_papers .== 1)
	println("Number of one-paper authors ($(k) database): ", onepaperers)
	println("Their proportion to all authors: ", onepaperers/length(no_papers))
	plotloglog(no_papers, k, "Number of papers per author")
	describe(no_papers)
end
```


The distribution of the number of authors per paper.

```julia
for k in keys(pubmats)
	no_coauthors = authornumbers(pubmats[k])
	plotloglog(no_coauthors, k, "Number of authors per paper")
	println(k, " database")
	describe(no_coauthors)
end
```

The distribution of the number of coauthors.

```julia
for k in keys(colnets)
	global no_coau = degree(colnets[k])
	hi_coau = histogram(no_coau)
	#plothistogram(hi_coau, xlab="Number of coauthors", ylab="Frequency")
	plotloglog(no_coau, k, "Number of coauthors")
	println("\n", k, " database")
	describe(no_coau)
end
```

The distribution of weights between coauthors.

```julia
for k in keys(colnets)
	println(k)
	W = Weights(colnets[k])
	hist(W, 0.0:0.010:1.0, label=k)
	xlabel("Edge weight")
	ylabel("Frequency")
	tight_layout()
	println("\n", k, " database")
	describe(W)
end
```

## Analysing !susgroups

```julia
for k in keys(colnets)
	d = describecartels(colnets[k])
	println("\n", k, " database")
	println(d)
	plothistogram(d["cartel_sizes"], plottitle="Frequency of cartel sizes",
		xlab="cartel size", ylab="relative frequency", relfreq=true)
end
```

```julia
function myECDF(x)
	xs = sort(x)
	y = (1:length(xs)) ./ length(xs)
	Dict(:xs => xs, :y => y)
end
rpubmat = Dict()
rcolmat = Dict()
rcolnet = Dict()
rpubmat[:dblp1] = read_scimat("dblp/dblppubmat-rewired-1.mat")
rpubmat[:MTMT1] = read_scimat("MTMT/MTMTpubmat-rewired-1.mat")
rcolmat[:dblp1] = read_scimat("dblp/dblpcolmat-rewired-1.mat")
rcolmat[:MTMT1] = read_scimat("MTMT/MTMTcolmat-rewired-1.mat")
rcolnet[:dblp1] = collaborationgraph(rcolmat[:dblp1])
rcolnet[:MTMT1] = collaborationgraph(rcolmat[:MTMT1])
Ws = Dict()
Ws[:dblp] = Weights(colnets[:dblp])
Ws[:MTMT] = Weights(colnets[:MTMT])
Ws[:dblp1] = Weights(rcolnet[:dblp1])
Ws[:MTMT1] = Weights(rcolnet[:MTMT1])
for k in keys(Ws)
	a = myECDF(Ws[k])
	#plot(log10.(a[:xs]), log10.(a[:y]), label=k)
	plot(a[:xs], a[:y], label=k)
end
legend()
Ws = Dict()
Ws[:dblp] = degree(colnets[:dblp])
Ws[:MTMT] = degree(colnets[:MTMT])
Ws[:dblp1] = degree(rcolnet[:dblp1])
Ws[:MTMT1] = degree(rcolnet[:MTMT1])
for k in sort(collect(keys(Ws)))
	plotloglog(Ws[k], k, "")
end
legend()
```


```julia
re_pubmat = Dict()
re_colmat = Dict()
for i in 1:20
	re_pubmat[i] = rewire(MTMTpubmat, 1_000_000)
	re_colmat[i] = collaborationmatrix(re_pubmat[i])
end
for i in 1:20
	println("MTMTpubmat_rewired-$(i).csv")
end
```



### Calculate publication measures

We calculate a couple of derived bibliographic measures for each author:

- number of papers
- total number of independent citations
- Hirsch index
- total number of coauthors
- number of D1 papers
- average number of citations per papers
- proportion of D1 papers
- number of papers weighted by
	- the equal contribution scheme
	- the sequence determined contribution scheme
	- the first, last author emphasis scheme
	- the bonus for first authorship scheme
	- the bonus for last authorship scheme
- number of independent citations weighted by the same schemes as used for the number of papers
- number of D1 papers weighted by the same schemes as used for the number of papers

```julia
sum.pubs <- NULL
for(s in papers.ls) {
	r <- calc.bib.measures(s)
	if(is.null(sum.pubs)) {
		sum.pubs <- data.frame(t(r))
	} else {
		sum.pubs <- rbind(sum.pubs, r)
	}
}
rownames(sum.pubs) <- names(papers.ls)
```



### Productivity of guilds

First we identify authors part of a guild in the productivity database.

```julia
full.au <- sum.pubs
guild.authors <- names(V(g.pubs.st.red))
non.guild.authors <- names(V(g.pubs))
non.guild.authors <- non.guild.authors[!(non.guild.authors %in%
																					 guild.authors)]
i <- rownames(full.au) %in% guild.authors
j <- rownames(full.au) %in% non.guild.authors

full.au$guild.member <- NA
full.au$guild.member[i] <- "yes"
full.au$guild.member[j] <- "no"
full.au$guild.member <- factor(full.au$guild.member)
```

Next, we compare the productivity of guilds to that of 'guilds' compiled from random individuals. We define the following function to do the calculations.

The first function calculates several measures of guild productivity. Guild productivity is measured for both the number of papers and citations. Guilds are characterised by (i) the total number of papers (and their citations) produced by the guild as a whole, (ii) the total number of papers (and their citations) produced by the guild members (in this case papers and citations can overlap between members), and (iii) the weighted numbers of papers (and their citations) produced by the members according to several scheme.

The second function generates `n.rep` guilds randomly compiled from authors not being member of any guilds and then calculates the above measures for each random guild.

The third function performs a randomisation test to see if the given measure for the focal guild differs from that of the random guilds.

The fourth function calculates the quantile of the guild measures relative to the distribution of random guild values.

```julia
guild.productivity <- function(guild, cikkek=papers.ls, szerzok=ee.prod) {
	g.cikkek <- cikkek[guild]
	p <- lapply(g.cikkek, function(sz) {x <- sz$citations; names(x) <- sz$id; x})
	pp <- lapply(g.cikkek, function(sz) {x <- sz$ranks; names(x) <- sz$id; x})
	d <- data.frame(n=unlist(sapply(p, names)), v=unlist(p), vv=unlist(pp))
	ud <- unique(d)
	r <- numeric()
	r["g.papers"] <- nrow(ud)
	r["g.citations"] <- sum(ud$v)
	r["g.D1"] <- sum(ud$vv == "D1")
	r["m.papers"] <- sum(szerzok[guild, "n.papers"])
	r["m.citations"] <- sum(szerzok[guild, "n.citations"])
	r["m.D1"] <- sum(szerzok[guild, "n.D1"])
	n <- names(szerzok)
	n <- n[grep("^w.*papers$", n)]
	for(nn in n) {
		r[nn] <- sum(szerzok[guild, nn])
		nc <- sub("papers$", "citations", nn)
		r[nc] <- sum(szerzok[guild, nc])
		nd <- sub("papers$", "D1", nn)
		r[nd] <- sum(szerzok[guild, nd])
	}
	r/length(guild)
}
rnd.guild.productivity <- function(guild.size, n.rep=1000, cikkek=papers.ls,
																		szerzok=ee.prod) {
	n.c.a <- rownames(szerzok)[szerzok$guild.member == "no"]
	res <- matrix(0, ncol=21, nrow=n.rep)
	for(i in 1:n.rep) {
		s <- sample(n.c.a, guild.size)
		r <- guild.productivity(s, cikkek=cikkek, szerzok=szerzok)
		res[i,] <- r
	}
	colnames(res) <- names(r)
	res
}
guild.productivity.test <- function(guild, p.value=0.05, cikkek=papers.ls,
																		szerzok=ee.prod) {
	res.g <- guild.productivity(guild, cikkek=cikkek, szerzok=szerzok)
	res.r <- rnd.guild.productivity(length(guild), 999, cikkek, szerzok)
	res.r <- rbind(res.g, res.r)
	value <- res.g
	l.crit <- numeric(ncol(res.r))
	u.crit <- numeric(ncol(res.r))
	for(i in 1:ncol(res.r)) {
		p <- quantile(res.r[,i], c(p.value/2, 1-p.value/2))
		l.crit[i] <- p[1]
		u.crit[i] <- p[2]
	}
	data.frame(value=res.g, l.crit=l.crit, u.crit=u.crit,
						 sig.mark=ifelse(l.crit < res.g & res.g < u.crit, "", "*"),
						 variable=names(res.g))
}
guild.productivity.q <- function(guild, p.value=0.05, n.rep=999,
																 cikkek=papers.ls, szerzok=ee.prod) {
	res.g <- guild.productivity(guild, cikkek=cikkek, szerzok=szerzok)
	res.r <- rnd.guild.productivity(length(guild), n.rep, cikkek, szerzok)
	res.r <- rbind(res.g, res.r)
	d <- numeric(ncol(res.r))
	m <- numeric(ncol(res.r))
	for(i in 1:ncol(res.r)) {
		d[i] <- sum(res.r[,i] > res.g[i])
		m[i] <- mean(res.r[,i])
	}
	data.frame(measure=names(res.g), value=res.g, rnd.mean=m,
						 quantile=d/nrow(res.r), guild.size=length(guild))
}
```

In the following we calculate the statistics for the guilds identified previously.

```julia
l.memb.red <- tapply(names(memb.red), memb.red, unique)
l <- sapply(l.memb.red, length)
i <- names(l.memb.red)[order(l, decreasing=TRUE)]
l.memb.red <- l.memb.red[i]
gd.file <- "guild_measures.Rdata"
if(file.exists(gd.file)) {
	load(gd.file)
} else {
	cl.p <- lapply(l.memb.red, guild.productivity.q, szerzok=full.au)
	cl.df <- data.frame()
	for(n in names(cl.p)) {
		l <- cl.p[[n]]
		l$guild <- n
		rownames(l) <- NULL
		cl.df <- rbind(cl.df, l)
	}
	cl.df$sig <- ifelse(cl.df$quantile > 0.975 | cl.df$quantile < 0.025, "*", "")
	cl.df$g2rnd <- cl.df$value/cl.df$rnd.mean
	save(cl.df, file=gd.file)
}
```

And finally, some analyses.

```julia
cits <- grepl("papers$", cl.df$measure)
m.papers <- lmer(log10(g2rnd) ~ measure + (1|guild), cl.df, subset=cits)
drop1(m.papers, test="Chisq")
summary(m.papers)
(em.p <- emmeans(m.papers, ~measure, type="response"))
pairs(em.p)
plot(em.p, horizontal=FALSE, xlab="measures", ylab="ratio of focal to random",
		 comparison=TRUE)
```

The result of the mixed effect model clearly shows that in guilds members achieve higher success if one considers success as the sum of the achievements documented individually (here number of papers) than when one measures the composite productivity of the whole guild. Even using the weighted individual measures does not help this situation. This analyses were based on all guilds identified.

```julia
cits <- grepl("citations$", cl.df$measure)
m.citations <- lmer(log10(g2rnd+1) ~ measure + (1|guild), cl.df, subset=cits)
drop1(m.citations, test="Chisq")
summary(m.citations)
(em.c <- emmeans(m.citations, ~measure, type="response"))
pairs(em.c)
plot(em.c, horizontal=FALSE, xlab="measures", ylab="ratio of focal to random",
		 comparison=TRUE)
```

Analysing the citation measures shows the same patterns, guild members have higher success if we consider their productivity independently from each other.

```julia
cits <- grepl("D1$", cl.df$measure)
m.D1 <- lmer(log10(g2rnd+1) ~ measure + (1|guild), cl.df, subset=cits)
drop1(m.D1, test="Chisq")
summary(m.D1)
(em.d <- emmeans(m.D1, ~measure, type="response"))
pairs(em.d)
plot(em.d, horizontal=FALSE, xlab="measures", ylab="ratio of focal to random",
		 comparison=TRUE)
```


We now analyse only those guilds which show higher than random productivity on the basis of the unweighted individual measure.

```julia
i <- grepl("^m\\.", cl.df$measure) & cl.df$g2rnd > 1
success.guilds <- as.character(cl.df$guild)[i]
i <- cl.df$guild %in% success.guilds
m.1 <- lmer(log10(g2rnd) ~ measure + (1|guild), cl.df, subset=i & !cits)
drop1(m.1, test="Chisq")
summary(m.1)
(em.1 <- emmeans(m.1, ~measure, type="response"))
pairs(em.1)
plot(em.1, horizontal=FALSE, xlab="measures", ylab="ratio of focal to random",
		 comparison=TRUE)
```

We arrived at the same conclusions; being part of a guild is advantageous if individual measures are considered.

### Diversity in cartels

A major difference between manufactures (groups where individuals with different skills work together) and cartels (group of individuals collude to increase publication counts) is the diversity of within group expertise. In manufactures one would expect a high diversity while in cartels individuals do the same. A further distinction can be the diversity of affiliations. In manufactures individuals can come from many different places, while in cartels they likely come from the same place. To make a distinction between these two work models we first download data about the authors and then analyse their expertise and their affiliation.

#### Download individuals' data

```julia
download.MTMT.authors.batch(as.character(author.info$mtmt.id))
```

Get the speciality.

```julia
json.list <- list.files(path="MTMT-downloads/", pattern=".*-author.json$",
												full.names=TRUE)
author.ls <- list()
for(f in json.list) {
	mtmt.id <- sub(".*\\/([0-9]+)_.*", "\\1", f)
	author.ls[[mtmt.id]] <- read.MTMT(f)
}
sci.fields <- sapply(author.ls,
										 function(a) if(is.null(a$auxName)) {NA} else {a$auxName})
sci.fields <- gsub("\\<a ", "", sci.fields)
sci.fields <- gsub("\\<és\\>", "", sci.fields)
sci.fields <- tolower(gsub("[-,)(]", "", sci.fields))
sci.fields <- gsub(" +", " ", sci.fields)
sci.ta <- sort(table(sci.fields))
names(sci.fields) <- sapply(as.numeric(names(sci.fields)), hash.id)
author.info$scientific.field <- NA
author.info[names(sci.fields), "scientific.field"] <- sci.fields
```

### Analyses of members

```julia
(w.papers <- wilcox.test(n.papers ~ guild.member, full.au))
(wi.ec.papers <- wilcox.test(w.ec.papers ~ guild.member, full.au))
layout(matrix(1:2, ncol=2))
boxplot(n.papers ~ guild.member, full.au, log="y", xlab="guild member",
				ylab="number of papers",
				main=paste("Wilcoxon p = ", round(w.papers$p.value, 3)))
boxplot(I(w.ec.papers+1) ~ guild.member, full.au, log="y",
				xlab="guild member", ylab="weighted number of papers",
				main=paste("Wilcoxon p = ", round(wi.ec.papers$p.value, 3)))
layout(1)

(w.citations <- wilcox.test(n.citations ~ guild.member, full.au))
(wi.ec.citations <- wilcox.test(w.ec.citations ~ guild.member, full.au))
layout(matrix(1:2, ncol=2))
boxplot(I(n.citations+1) ~ guild.member, full.au, log="y",
				xlab="guild member", ylab="number of citations",
				main=paste("Wilcoxon p = ", round(w.citations$p.value, 3)))
boxplot(I(w.ec.citations+1) ~ guild.member, full.au, log="y",
				xlab="guild member", ylab="weighted number of citations",
				main=paste("Wilcoxon p = ", round(wi.ec.citations$p.value, 3)))
layout(1)

(w.D1 <- wilcox.test(n.D1 ~ guild.member, full.au))
(wi.ec.D1 <- wilcox.test(w.ec.D1 ~ guild.member, full.au))
layout(matrix(1:2, ncol=2))
boxplot(I(n.D1+1) ~ guild.member, full.au, log="y",
				xlab="guild member", ylab="number of D1 papers",
				main=paste("Wilcoxon p = ", round(w.D1$p.value, 3)))
boxplot(I(w.ec.D1+1) ~ guild.member, full.au, log="y",
				xlab="guild member", ylab="weighted number of D1 papers",
				main=paste("Wilcoxon p = ", round(wi.ec.D1$p.value, 3)))
layout(1)
```

Authors in guild are more affected by weighting productivity.

Next we investigate, how the authors rank changes if switch from unweighted to weighted publication measures.

```julia
par(xpd=FALSE)
r.n.papers <- rank(full.au$n.papers)
r.flae.papers <- rank(full.au$w.flae.papers)
d.r <- r.flae.papers - r.n.papers
(w <- wilcox.test(d.r ~ guild.member, full.au))
boxplot(d.r ~ guild.member, full.au, xlab="guild member",
				ylab="change in rank: number of papers",
				main=paste("Wilcoxon p =", round(w$p.value, 3)))
abline(h=0, lty=2)

r.n.citations <- rank(full.au$n.citations)
r.flae.citations <- rank(full.au$w.flae.citations)
d.r <- r.flae.citations - r.n.citations
(w <- wilcox.test(d.r ~ guild.member, full.au))
boxplot(d.r ~ guild.member, full.au, xlab="guild member",
				ylab="change in rank: number of citations",
				main=paste("Wilcoxon p =", round(w$p.value, 4)))
abline(h=0, lty=2)

r.n.D1 <- rank(full.au$n.D1)
r.flae.D1 <- rank(full.au$w.flae.D1)
d.r <- r.flae.D1 - r.n.D1
(w <- wilcox.test(d.r ~ guild.member, full.au))
boxplot(d.r ~ guild.member, full.au, xlab="guild member",
				ylab="change in rank: number of D1 papers",
				main=paste("Wilcoxon p =", round(w$p.value, 4)))
abline(h=0, lty=2)
```

Here below, compare how the ranks of authors change when switching from unweighted to weighted measures, but now we compare authors of similar ranks.

```julia
o <- order(r.n.papers)
cm <- full.au$guild.member[o]
dr <- d.r[o]
i.c <- (1:nrow(full.au))[cm == "yes"]
i.c <- i.c[!is.na(i.c)]
i.p <- i.c - 1
i.p <- i.p[cm[i.p] == "no"]
i.n <- i.c + 1
i.n <- i.n[cm[i.n] == "no"]
(w <- wilcox.test(dr[i.c], c(dr[i.n],dr[i.p])))
boxplot(list(no=c(dr[i.p], dr[i.n]), yes=dr[i.c]), xlab="guild member",
				ylab="change in rank: number of papers",
				main=paste("Wilcoxon p =", round(w$p.value, 4)))
abline(h=0, lty=2)

o <- order(r.n.citations)
cm <- full.au$guild.member[o]
dr <- d.r[o]
i.c <- (1:nrow(full.au))[cm == "yes"]
i.c <- i.c[!is.na(i.c)]
i.p <- i.c - 1
i.p <- i.p[cm[i.p] == "no"]
i.n <- i.c + 1
i.n <- i.n[cm[i.n] == "no"]
(w <- wilcox.test(dr[i.c], c(dr[i.n],dr[i.p])))
boxplot(list(no=c(dr[i.p], dr[i.n]), yes=dr[i.c]), xlab="guild member",
				ylab="change in rank: number of citations",
				main=paste("Wilcoxon p =", round(w$p.value, 4)))
abline(h=0, lty=2)

o <- order(r.n.D1)
cm <- full.au$guild.member[o]
dr <- d.r[o]
i.c <- (1:nrow(full.au))[cm == "yes"]
i.c <- i.c[!is.na(i.c)]
i.p <- i.c - 1
i.p <- i.p[cm[i.p] == "no"]
i.n <- i.c + 1
i.n <- i.n[cm[i.n] == "no"]
(w <- wilcox.test(dr[i.c], c(dr[i.n],dr[i.p])))
boxplot(list(no=c(dr[i.p], dr[i.n]), yes=dr[i.c]), xlab="guild member",
				ylab="change in rank: number of D1 papers",
				main=paste("Wilcoxon p =", round(w$p.value, 4)))
abline(h=0, lty=2)

```

#### Correlates of being a strong component member

```julia
library(randomForest)
ee.prod <- full.au[!is.na(full.au$guild.member),]
ee.RF <- randomForest(guild.member ~ ., ee.prod, importance=TRUE)
varImpPlot(ee.RF)
l.ee.prod <- as.data.frame(lapply(ee.prod[,-ncol(ee.prod)],
																	function(x) log10(x+1)))
l.ee.prod$betweenness <- betweenness(g.pubs)
l.ee.prod$strength <- strength(g.pubs)
l.ee.prod$closeness <- closeness(g.pubs)
l.ee.prod$degree <- degree(g.pubs)
l.ee.prod$guild.member <- ee.prod$guild.member
l.ee.RF <- randomForest(guild.member ~ ., l.ee.prod, importance=TRUE)
varImpPlot(l.ee.RF)
p.cl <- predict(l.ee.RF)
table(p.cl, l.ee.prod$guild.member)
partialPlot(l.ee.RF, l.ee.prod, "strength")
```


# The dblp dataset

We downloaded the [dblp publication database](https://dblp.org), which covers computational sciences. Then we extracted all article records from the database `xml` which have a `doi.org` id. During the extraction we dropped all but the `author`, `year` and `doi` fields. The process is documented in `dblp-data/Makefile`. We use the resulted `dblp-data/dblp-articles.txt` here.

## Load the dblp dataset

Now we load the dataset.

```julia
dblp_file = joinpath(pwd(), "dblp-data", "dblp-articles.txt")
lines = read_dblprecords(dblp_file)
@time parecsdblp = recordpapers(lines, 2001, 2002);
@time dblppubmat, dblpauids = recs2pubmat(parecsdblp);
write_spmatrix("dblppubmat.csv", dblppubmat)
@time dblpcolmat = collaborationmatrix(dblppubmat);
write_spmatrix("dblpcolmat.csv", dblpcolmat)
@time dblpcolnet = collaborationgraph(dblpcolmat);
```

## Some description about the dataset

The dblp dataset contains more than one and half million records. The distribution of articles over the years is as follows.

```julia
years <- sapply(dblp.ls, function(y) y$year)
plot(table(years), ylab="number of articles")
```

The distribution of number of authors by articles.

```julia
n.authors <- sapply(dblp.ls, function(y) length(y$authors))
plot(table(n.authors))
plot.loglog(n.authors, pch=16, bty="l", xlab="number of authors per paper",
						ylab="frequency")
```

The number of distinct authors in the dataset:

```julia
d.authors <- unlist(lapply(dblp.ls, function(y) y$authors))
length(d.authors)
length(unique(d.authors))
t.authors <- table(d.authors)
t.authors <- sort(t.authors)
plot.loglog(as.numeric(t.authors), pch=16, bty="l",
		 xlab="number of papers per author", ylab="frequency")
```

## Reducing the dblp dataset

We have a huge number of articles so for the first time we concentrate only articles between 2001 and 2010.

```julia
years <- as.numeric(years)
i <- years >= 2001 & years <= 2010
sum(i)
dblp.red <- dblp.ls[i]
rm("dblp.ls")
gc()
```

This is still a huge number, but we make a try.

```julia
n.authors <- sapply(dblp.red, function(y) length(y$authors))
plot(table(n.authors))
plot.loglog(n.authors, pch=16, bty="l", xlab="number of authors per paper",
						ylab="frequency")
```


```julia
a.authors <- unlist(lapply(dblp.red, function(y) y$authors))
length(a.authors)
d.authors <- unique(a.authors)
length(d.authors)
t.authors <- table(a.authors)
t.authors <- sort(t.authors)
plot.loglog(as.numeric(t.authors), pch=16, bty="l",
		 xlab="number of papers per author", ylab="frequency")
```

## Process the article data

We are create a sparse matrix and fill it with the coauthorship data.

```julia
p.ls <- dblp.red[1:100]
d.authors <- unique(unlist(lapply(p.ls, function(y) y$authors)))
d.mat <- Matrix(0.0, ncol=length(d.authors), nrow=length(d.authors))
colnames(d.mat) <- d.authors
rownames(d.mat) <- d.authors
for(p in p.ls) {
	n.a <- length(p$authors)
	for(a in p$authors) {
		d.mat[a, a] <- d.mat[a, a] + 1
	}
	if(n.a > 1) {
		for(i in 1:(n.a-1)) {
			a1 <- p$authors[i]
			for(j in (i+1):n.a) {
				a2 <- p$authors[j]
				d.mat[a1, a2] <- d.mat[a1, a2] + 1
			}
		}
	}
}
for(i  in 1:(ncol(d.mat)-1)) {
	for(j in (i+1):ncol(d.mat)) {
		d.sec <- d.mat[i,j] + d.mat[j,i]
		if(d.sec > 0) {
			d.uni <- d.mat[i, i] + d.mat[j, j] - d.sec
			d.mat[i, j] <- d.sec/d.uni
			d.mat[j, i] <- 0
		}
	}
}
g.dblp <- graph.adjacency(d.mat, mode="upper", weighted=TRUE, diag=FALSE)
```



# End matters

```julia
sessionInfo()
```

<!-- vim: set foldmethod=syntax: -->
